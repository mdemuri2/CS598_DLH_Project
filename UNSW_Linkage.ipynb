{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source of Code:\n",
    "This code reproduces the results of the “Statistical supervised meta-ensemble algorithm for medical record linkage” paper. The vast majority of this code was sourced from the original paper’s GitHub repository. The original code has been slightly modified and amended. Specifically, the author's code has been amended to run the experiment 10 times. The mean and standard deviation of the 10 results were recorded.\n",
    "\n",
    "K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "\n",
    "# Source of Dataset:\n",
    "The FEBRL datasets used in this experiment trial were the febrl3_UNSW.csv and febrl4_UNSW.csv files produced by the Preparing_FEBRL_and_ePBRN_Datasets.ipynb file. These FEBRL datasets are slightly different than the FEBRL datasets published on the author's GitHub repository https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.  This is because the FEBRL datasets are generated using the Python Record Linkage Toolkit library. As a result, the generated dataset is dependent on the version of Python Record Linkage Toolkit library at the time.  When consulting with Jitendra Jonnagaddala, one of the paper's authors, it was stated that a reasonable explanation for this observed difference between the FEBRL datasets published on the authors' GitHub and the current regeneration of the datasets using the Python Record Linkage Toolkit library was due to changes in the library. The paper was published in 2019 and the most recent change to the library was committed on April 19, 2022. https://github.com/J535D165/recordlinkage\n",
    "\n",
    "The ePBRN datasets used in this experiment trail were the ePBRN_D_dup.csv and ePBRN_F_dup.csv files produced by the Preparing_FEBRL_and_ePBRN_Datasets.ipynb file. <span style=\"color:red\">As noted in the Preparing_FEBRL_and_ePBRN_Datasets.ipynb file, one of the authors Jitendra Jonnagaddala stated that these ePBRN datasets ( ePBRN_D_dup.csv and ePBRN_F_dup.csv) are not reflective of the ePBRN datasets used in the study. Approved clearance would be needed to attain the ePBRN datasets used in the study.</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 s, sys: 643 ms, total: 3.21 s\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Source: \n",
    "K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "'''\n",
    "import recordlinkage as rl, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from recordlinkage.preprocessing import phonetic\n",
    "from numpy.random import choice\n",
    "import collections, numpy\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from math import comb\n",
    "import statistics\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 FEBRL Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 1e+03 ns, total: 12 µs\n",
      "Wall time: 14.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Source: \n",
    "K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "'''\n",
    "def generate_true_links(df): \n",
    "    # although the match_id column is included in the original df to imply the true links,\n",
    "    # this function will create the true_link object identical to the true_links properties\n",
    "    # of recordlinkage toolkit, in order to exploit \"Compare.compute()\" from that toolkit\n",
    "    # in extract_function() for extracting features quicker.\n",
    "    # This process should be deprecated in the future release of the UNSW toolkit.\n",
    "    df[\"rec_id\"] = df.index.values.tolist()\n",
    "    indices_1 = []\n",
    "    indices_2 = []\n",
    "    processed = 0\n",
    "    for match_id in df[\"match_id\"].unique():\n",
    "        if match_id != -1:    \n",
    "            processed = processed + 1\n",
    "            # print(\"In routine generate_true_links(), count =\", processed)\n",
    "            # clear_output(wait=True)\n",
    "            linkages = df.loc[df['match_id'] == match_id]\n",
    "            for j in range(len(linkages)-1):\n",
    "                for k in range(j+1, len(linkages)):\n",
    "                    indices_1 = indices_1 + [linkages.iloc[j][\"rec_id\"]]\n",
    "                    indices_2 = indices_2 + [linkages.iloc[k][\"rec_id\"]]    \n",
    "    links = pd.MultiIndex.from_arrays([indices_1,indices_2])\n",
    "    return links\n",
    "\n",
    "def generate_false_links(df, size):\n",
    "    # A counterpart of generate_true_links(), with the purpose to generate random false pairs\n",
    "    # for training. The number of false pairs in specified as \"size\".\n",
    "    df[\"rec_id\"] = df.index.values.tolist()\n",
    "    indices_1 = []\n",
    "    indices_2 = []\n",
    "    unique_match_id = df[\"match_id\"].unique()\n",
    "    for j in range(size):\n",
    "            false_pair_ids = choice(unique_match_id, 2)\n",
    "            candidate_1_cluster = df.loc[df['match_id'] == false_pair_ids[0]]\n",
    "            candidate_1 = candidate_1_cluster.iloc[choice(range(len(candidate_1_cluster)))]\n",
    "            candidate_2_cluster = df.loc[df['match_id'] == false_pair_ids[1]]\n",
    "            candidate_2 = candidate_2_cluster.iloc[choice(range(len(candidate_2_cluster)))]    \n",
    "            indices_1 = indices_1 + [candidate_1[\"rec_id\"]]\n",
    "            indices_2 = indices_2 + [candidate_2[\"rec_id\"]]  \n",
    "    links = pd.MultiIndex.from_arrays([indices_1,indices_2])\n",
    "    return links\n",
    "\n",
    "def swap_fields_flag(f11, f12, f21, f22):\n",
    "    return int((f11 == f22) and (f12 == f21))\n",
    "\n",
    "def extract_features(df, links):\n",
    "    c = rl.Compare()\n",
    "    c.string('given_name', 'given_name', method='jarowinkler', label='y_name')\n",
    "    c.string('given_name_soundex', 'given_name_soundex', method='jarowinkler', label='y_name_soundex')\n",
    "    c.string('given_name_nysiis', 'given_name_nysiis', method='jarowinkler', label='y_name_nysiis')\n",
    "    c.string('surname', 'surname', method='jarowinkler', label='y_surname')\n",
    "    c.string('surname_soundex', 'surname_soundex', method='jarowinkler', label='y_surname_soundex')\n",
    "    c.string('surname_nysiis', 'surname_nysiis', method='jarowinkler', label='y_surname_nysiis')\n",
    "    c.exact('street_number', 'street_number', label='y_street_number')\n",
    "    c.string('address_1', 'address_1', method='levenshtein', threshold=0.7, label='y_address1')\n",
    "    c.string('address_2', 'address_2', method='levenshtein', threshold=0.7, label='y_address2')\n",
    "    c.exact('postcode', 'postcode', label='y_postcode')\n",
    "    c.exact('day', 'day', label='y_day')\n",
    "    c.exact('month', 'month', label='y_month')\n",
    "    c.exact('year', 'year', label='y_year')\n",
    "        \n",
    "    # Build features\n",
    "    feature_vectors = c.compute(links, df, df)\n",
    "    return feature_vectors\n",
    "\n",
    "def generate_train_X_y(df):\n",
    "    # This routine is to generate the feature vector X and the corresponding labels y\n",
    "    # with exactly equal number of samples for both classes to train the classifier.\n",
    "    pos = extract_features(df, train_true_links)\n",
    "    train_false_links = generate_false_links(df, len(train_true_links))    \n",
    "    neg = extract_features(df, train_false_links)\n",
    "    X = pos.values.tolist() + neg.values.tolist()\n",
    "    y = [1]*len(pos)+[0]*len(neg)\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def train_model(modeltype, modelparam, train_vectors, train_labels, modeltype_2):\n",
    "    if modeltype == 'svm': # Support Vector Machine\n",
    "        model = svm.SVC(C = modelparam, kernel = modeltype_2)\n",
    "        model.fit(train_vectors, train_labels) \n",
    "    elif modeltype == 'lg': # Logistic Regression\n",
    "        model = LogisticRegression(C=modelparam, penalty = modeltype_2,class_weight=None, dual=False, fit_intercept=True, \n",
    "                                   intercept_scaling=1, max_iter=5000, multi_class='ovr', \n",
    "                                   n_jobs=1, random_state=None)\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    elif modeltype == 'nb': # Naive Bayes\n",
    "        model = GaussianNB()\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    elif modeltype == 'nn': # Neural Network\n",
    "        model = MLPClassifier(solver='lbfgs', alpha=modelparam, hidden_layer_sizes=(256, ), \n",
    "                              activation = modeltype_2,random_state=None, batch_size='auto', \n",
    "                              learning_rate='constant',  learning_rate_init=0.001, \n",
    "                              power_t=0.5, max_iter=10000, shuffle=True, \n",
    "                              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                              nesterovs_momentum=True, early_stopping=False, \n",
    "                              validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    return model\n",
    "\n",
    "def classify(model, test_vectors):\n",
    "    result = model.predict(test_vectors)\n",
    "    return result\n",
    "\n",
    "    \n",
    "def evaluation(test_labels, result):\n",
    "    true_pos = np.logical_and(test_labels, result)\n",
    "    count_true_pos = np.sum(true_pos)\n",
    "    true_neg = np.logical_and(np.logical_not(test_labels),np.logical_not(result))\n",
    "    count_true_neg = np.sum(true_neg)\n",
    "    false_pos = np.logical_and(np.logical_not(test_labels), result)\n",
    "    count_false_pos = np.sum(false_pos)\n",
    "    false_neg = np.logical_and(test_labels,np.logical_not(result))\n",
    "    count_false_neg = np.sum(false_neg)\n",
    "    precision = count_true_pos/(count_true_pos+count_false_pos)\n",
    "    sensitivity = count_true_pos/(count_true_pos+count_false_neg) # sensitivity = recall\n",
    "    confusion_matrix = [count_true_pos, count_false_pos, count_false_neg, count_true_neg]\n",
    "    no_links_found = np.count_nonzero(result)\n",
    "    no_false = count_false_pos + count_false_neg\n",
    "    Fscore = 2*precision*sensitivity/(precision+sensitivity)\n",
    "    metrics_result = {'no_false':no_false, 'confusion_matrix':confusion_matrix ,'precision':precision,\n",
    "                     'sensitivity':sensitivity ,'no_links':no_links_found, 'F-score': Fscore}\n",
    "    return metrics_result\n",
    "\n",
    "def blocking_performance(candidates, true_links, df):\n",
    "    count = 0\n",
    "    for candi in candidates:\n",
    "        if df.loc[candi[0]][\"match_id\"]==df.loc[candi[1]][\"match_id\"]:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 FEBRL Running the Experiment 10 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FEBRL_surname_nc = []\n",
    "FEBRL_surname_pc = []\n",
    "FEBRL_surname_rr = []\n",
    "FEBRL_given_name_nc = []\n",
    "FEBRL_given_name_pc = []\n",
    "FEBRL_given_name_rr = []\n",
    "FEBRL_postcode_nc = []\n",
    "FEBRL_postcode_pc = []\n",
    "FEBRL_postcode_rr = []\n",
    "FEBRL_all_nc = []\n",
    "FEBRL_all_pc = []\n",
    "FEBRL_all_rr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 µs, sys: 1e+03 ns, total: 17 µs\n",
      "Wall time: 21.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FEBRL_svm_pr = []\n",
    "FEBRL_svm_re = []\n",
    "FEBRL_svm_fs = []\n",
    "FEBRL_svm_fc = []\n",
    "FEBRL_svm_bag_pr = []\n",
    "FEBRL_svm_bag_re = []\n",
    "FEBRL_svm_bag_fs = []\n",
    "FEBRL_svm_bag_fc = []\n",
    "FEBRL_nn_pr = []\n",
    "FEBRL_nn_re = []\n",
    "FEBRL_nn_fs = []\n",
    "FEBRL_nn_fc = []\n",
    "FEBRL_nn_bag_pr = []\n",
    "FEBRL_nn_bag_re = []\n",
    "FEBRL_nn_bag_fs = []\n",
    "FEBRL_nn_bag_fc = []\n",
    "FEBRL_lr_pr = []\n",
    "FEBRL_lr_re = []\n",
    "FEBRL_lr_fs = []\n",
    "FEBRL_lr_fc = []\n",
    "FEBRL_lr_bag_pr = []\n",
    "FEBRL_lr_bag_re = []\n",
    "FEBRL_lr_bag_fs = []\n",
    "FEBRL_lr_bag_fc = []\n",
    "FEBRL_ensemble_pr = []\n",
    "FEBRL_ensemble_re = []\n",
    "FEBRL_ensemble_fs = []\n",
    "FEBRL_ensemble_fc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ITERATION:  0\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  1\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  2\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  3\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  4\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  5\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  6\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  7\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  8\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  9\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 5000 , number of matched pairs:  1165\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "CPU times: user 52min 33s, sys: 1min 20s, total: 53min 54s\n",
      "Wall time: 45min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    print(\"\")\n",
    "    print(\"ITERATION: \", i)\n",
    "    print(\"\")\n",
    "\n",
    "    trainset = 'febrl3_UNSW'\n",
    "    testset = 'febrl4_UNSW'\n",
    "    \n",
    "    # 1. Preparing the FEBRL dataset #################################################################################\n",
    "    print(\"Preparing the FEBRL dataset\")\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    # Import\n",
    "    print(\"Import train set...\")\n",
    "    df_train = pd.read_csv(trainset+\".csv\", index_col = \"rec_id\")\n",
    "    train_true_links = generate_true_links(df_train)\n",
    "    print(\"Train set size:\", len(df_train), \", number of matched pairs: \", str(len(train_true_links)))\n",
    "\n",
    "    # Preprocess train set\n",
    "    df_train['postcode'] = df_train['postcode'].astype(str)\n",
    "    df_train['given_name_soundex'] = phonetic(df_train['given_name'], method='soundex')\n",
    "    df_train['given_name_nysiis'] = phonetic(df_train['given_name'], method='nysiis')\n",
    "    df_train['surname_soundex'] = phonetic(df_train['surname'], method='soundex')\n",
    "    df_train['surname_nysiis'] = phonetic(df_train['surname'], method='nysiis')\n",
    "\n",
    "    # Final train feature vectors and labels\n",
    "    X_train, y_train = generate_train_X_y(df_train)\n",
    "    print(\"Finished building X_train, y_train\")\n",
    "    \n",
    "    # 2. FEBRL Blocking Results ######################################################################################\n",
    "    print(\"FEBRL Blocking Results\")\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "\n",
    "    Code has been modified to reproduce and print Table 4 of the paper.\n",
    "    '''\n",
    "    # Blocking Criteria: declare non-match of all of the below fields disagree\n",
    "    # Import\n",
    "    print(\"Import test set...\")\n",
    "    FEBRL_blocking_results = []\n",
    "    df_test = pd.read_csv(testset+\".csv\", index_col = \"rec_id\")\n",
    "    test_true_links = generate_true_links(df_test)\n",
    "    leng_test_true_links = len(test_true_links)\n",
    "    print(\"Test set size:\", len(df_test), \", number of matched pairs: \", str(leng_test_true_links))\n",
    "\n",
    "    total_possible_pairs = comb(len(df_test),2)\n",
    "    match_pairs = leng_test_true_links\n",
    "\n",
    "    print(\"BLOCKING PERFORMANCE:\")\n",
    "    blocking_fields = [\"given_name\", \"surname\", \"postcode\"]\n",
    "    all_candidate_pairs = []\n",
    "    for field in blocking_fields:\n",
    "        block_indexer = rl.BlockIndex(on=field)\n",
    "        candidates = block_indexer.index(df_test)\n",
    "        detects = blocking_performance(candidates, test_true_links, df_test)\n",
    "        all_candidate_pairs = candidates.union(all_candidate_pairs)\n",
    "        print(\"Number of pairs of matched \"+ field +\": \"+str(len(candidates)), \", detected \",\n",
    "             detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "              str(leng_test_true_links-detects) )\n",
    "        \n",
    "        # recording results for iteration\n",
    "        if field == 'given_name':\n",
    "            FEBRL_given_name_nc.append(len(candidates))\n",
    "            FEBRL_given_name_pc.append(detects/match_pairs*100.0)\n",
    "            FEBRL_given_name_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)\n",
    "        if field == 'surname':\n",
    "            FEBRL_surname_nc.append(len(candidates))\n",
    "            FEBRL_surname_pc.append(detects/match_pairs*100.0)\n",
    "            FEBRL_surname_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)\n",
    "        if field == 'postcode':\n",
    "            FEBRL_postcode_nc.append(len(candidates))\n",
    "            FEBRL_postcode_pc.append(detects/match_pairs*100.0)\n",
    "            FEBRL_postcode_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)  \n",
    "\n",
    "    detects = blocking_performance(all_candidate_pairs, test_true_links, df_test)\n",
    "    print(\"Number of pairs of at least 1 field matched: \" + str(len(all_candidate_pairs)), \", detected \",\n",
    "         detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "              str(leng_test_true_links-detects) )\n",
    "    \n",
    "    # recording results for iteration\n",
    "    FEBRL_all_nc.append(len(all_candidate_pairs))\n",
    "    FEBRL_all_pc.append(detects/match_pairs*100.0)\n",
    "    FEBRL_all_rr.append((1-(len(all_candidate_pairs)/1.0/total_possible_pairs))*100)\n",
    "    \n",
    "    # 3. FEBRL Classification Performance Results ####################################################################\n",
    "    print(\"FEBRL Classification Performance Results\")\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    ## TEST SET CONSTRUCTION\n",
    "    # Preprocess test set\n",
    "    print(\"Processing test set...\")\n",
    "    print(\"Preprocess...\")\n",
    "    df_test['postcode'] = df_test['postcode'].astype(str)\n",
    "    df_test['given_name_soundex'] = phonetic(df_test['given_name'], method='soundex')\n",
    "    df_test['given_name_nysiis'] = phonetic(df_test['given_name'], method='nysiis')\n",
    "    df_test['surname_soundex'] = phonetic(df_test['surname'], method='soundex')\n",
    "    df_test['surname_nysiis'] = phonetic(df_test['surname'], method='nysiis')\n",
    "\n",
    "    # Test feature vectors and labels construction\n",
    "    print(\"Extract feature vectors...\")\n",
    "    df_X_test = extract_features(df_test, all_candidate_pairs)\n",
    "    vectors = df_X_test.values.tolist()\n",
    "    labels = [0]*len(vectors)\n",
    "    feature_index = df_X_test.index\n",
    "    for i in range(0, len(feature_index)):\n",
    "        if df_test.loc[feature_index[i][0]][\"match_id\"]==df_test.loc[feature_index[i][1]][\"match_id\"]:\n",
    "            labels[i] = 1\n",
    "    X_test, y_test = shuffle(vectors, labels, random_state=0)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    print(\"Count labels of y_test:\",collections.Counter(y_test))\n",
    "    print(\"Finished building X_test, y_test\")\n",
    "\n",
    "    '''\n",
    "    Modifying the code provided by the authors to produce the results in Table 6 of the paper. \n",
    "    Used the hyperparameters as specified by Table 5 of the paper to build the models.\n",
    "\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    # 3.1 SVM BASE LEARNERS CLASSIFICATION AND EVALUATION ############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for SVM on the FEBRL dataset\n",
    "    1. Linear kernel\n",
    "    2. C = 0.005\n",
    "    '''\n",
    "    modeltype = 'svm' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'linear'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 0.005\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false  = final_eval['no_false']\n",
    "    \n",
    "    FEBRL_svm_pr.append(precision)\n",
    "    FEBRL_svm_re.append(sensitivity)\n",
    "    FEBRL_svm_fs.append(Fscore)\n",
    "    FEBRL_svm_fc.append(nb_false)\n",
    "\n",
    "    # 3.2 NN BASE LEARNERS CLASSIFICATION AND EVALUATION #############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for NN on the FEBRL dataset\n",
    "    1. ReLu activation with a = 100\n",
    "    '''\n",
    "    modeltype = 'nn' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'relu'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 100\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false = final_eval['no_false']\n",
    "    \n",
    "    FEBRL_nn_pr.append(precision)\n",
    "    FEBRL_nn_re.append(sensitivity)\n",
    "    FEBRL_nn_fs.append(Fscore)\n",
    "    FEBRL_nn_fc.append(nb_false)\n",
    "\n",
    "    # 3.3 LR BASE LEARNERS CLASSIFICATION AND EVALUATION #############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for NN on the FEBRL dataset\n",
    "    1. Regularization I2\n",
    "    2. C = 0.2\n",
    "    '''\n",
    "    modeltype = 'lg' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'l2'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 0.2\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false = final_eval['no_false']\n",
    "    \n",
    "    FEBRL_lr_pr.append(precision)\n",
    "    FEBRL_lr_re.append(sensitivity)\n",
    "    FEBRL_lr_fs.append(Fscore)\n",
    "    FEBRL_lr_fc.append(nb_false)\n",
    "    \n",
    "    # 3.4 BAGGING BASE LEARNERS CLASSIFICATION AND EVALUATION ########################################################\n",
    "    modeltypes = ['svm', 'nn', 'lg'] \n",
    "    modeltypes_2 = ['linear', 'relu', 'l2']\n",
    "    modelparams = [0.005, 100, 0.2]\n",
    "    nFold = 10\n",
    "    kf = KFold(n_splits=nFold)\n",
    "    model_raw_score = [0]*3\n",
    "    model_binary_score = [0]*3\n",
    "    model_i = 0\n",
    "    for model_i in range(3):\n",
    "        modeltype = modeltypes[model_i]\n",
    "        modeltype_2 = modeltypes_2[model_i]\n",
    "        modelparam = modelparams[model_i]\n",
    "        # print(modeltype, \"per fold:\")\n",
    "        iFold = 0\n",
    "        result_fold = [0]*nFold\n",
    "        final_eval_fold = [0]*nFold\n",
    "        for train_index, valid_index in kf.split(X_train):\n",
    "            X_train_fold = X_train[train_index]\n",
    "            y_train_fold = y_train[train_index]\n",
    "            md =  train_model(modeltype, modelparam, X_train_fold, y_train_fold, modeltype_2)\n",
    "            result_fold[iFold] = classify(md, X_test)\n",
    "            final_eval_fold[iFold] = evaluation(y_test, result_fold[iFold])\n",
    "            # print(\"Fold\", str(iFold), final_eval_fold[iFold])\n",
    "            iFold = iFold + 1\n",
    "        bagging_raw_score = np.average(result_fold, axis=0)\n",
    "        bagging_binary_score  = np.copy(bagging_raw_score)\n",
    "        bagging_binary_score[bagging_binary_score > 0.5] = 1\n",
    "        bagging_binary_score[bagging_binary_score <= 0.5] = 0\n",
    "        bagging_eval = evaluation(y_test, bagging_binary_score)\n",
    "        # print(modeltype, \"bagging:\", bagging_eval)\n",
    "        # print('')\n",
    "\n",
    "        if modeltype == 'svm':\n",
    "            FEBRL_svm_bag_pr.append(bagging_eval['precision'])\n",
    "            FEBRL_svm_bag_re.append(bagging_eval['sensitivity'])\n",
    "            FEBRL_svm_bag_fs.append(bagging_eval['F-score'])\n",
    "            FEBRL_svm_bag_fc.append(bagging_eval['no_false'])\n",
    "        elif modeltype == 'nn':\n",
    "            FEBRL_nn_bag_pr.append(bagging_eval['precision'])\n",
    "            FEBRL_nn_bag_re.append(bagging_eval['sensitivity'])\n",
    "            FEBRL_nn_bag_fs.append(bagging_eval['F-score'])\n",
    "            FEBRL_nn_bag_fc.append(bagging_eval['no_false'])   \n",
    "        elif modeltype == 'lg':\n",
    "            FEBRL_lr_bag_pr.append(bagging_eval['precision'])\n",
    "            FEBRL_lr_bag_re.append(bagging_eval['sensitivity'])\n",
    "            FEBRL_lr_bag_fs.append(bagging_eval['F-score'])\n",
    "            FEBRL_lr_bag_fc.append(bagging_eval['no_false'])\n",
    "\n",
    "        model_raw_score[model_i] = bagging_raw_score\n",
    "        model_binary_score[model_i] = bagging_binary_score\n",
    "        \n",
    "    # 4 Ensemble Model Performance ###################################################################################\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    thres = .99\n",
    "\n",
    "    stack_raw_score = np.average(model_raw_score, axis=0)\n",
    "    stack_binary_score = np.copy(stack_raw_score)\n",
    "    stack_binary_score[stack_binary_score > thres] = 1\n",
    "    stack_binary_score[stack_binary_score <= thres] = 0\n",
    "    stacking_eval = evaluation(y_test, stack_binary_score)\n",
    "    \n",
    "    FEBRL_ensemble_pr.append(stacking_eval['precision'])\n",
    "    FEBRL_ensemble_re.append(stacking_eval['sensitivity'])\n",
    "    FEBRL_ensemble_fs.append(stacking_eval['F-score'])\n",
    "    FEBRL_ensemble_fc.append(stacking_eval['no_false'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 FEBRL Results: Creating Paper’s Table 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 FEBRL Mean of blocking performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 123 µs, sys: 1e+03 ns, total: 124 µs\n",
      "Wall time: 17.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "results.append(sum(FEBRL_surname_nc) / float(len(FEBRL_surname_nc)))\n",
    "results.append(sum(FEBRL_surname_pc) / float(len(FEBRL_surname_pc)))\n",
    "results.append(sum(FEBRL_surname_rr) / float(len(FEBRL_surname_rr)))\n",
    "results.append(sum(FEBRL_given_name_nc) / float(len(FEBRL_given_name_nc)))\n",
    "results.append(sum(FEBRL_given_name_pc) / float(len(FEBRL_given_name_pc)))\n",
    "results.append(sum(FEBRL_given_name_rr) / float(len(FEBRL_given_name_rr)))\n",
    "results.append(sum(FEBRL_postcode_nc) / float(len(FEBRL_postcode_nc)))\n",
    "results.append(sum(FEBRL_postcode_pc) / float(len(FEBRL_postcode_pc)))\n",
    "results.append(sum(FEBRL_postcode_rr) / float(len(FEBRL_postcode_rr)))\n",
    "results.append(sum(FEBRL_all_nc) / float(len(FEBRL_all_nc)))\n",
    "results.append(sum(FEBRL_all_pc) / float(len(FEBRL_all_pc)))\n",
    "results.append(sum(FEBRL_all_rr) / float(len(FEBRL_all_rr)))\n",
    "\n",
    "blocking_criterion = ['Surname', 'Surname', 'Surname', \n",
    "                      'Given name', 'Given name', 'Given name',\n",
    "                      'Postcode', 'Postcode', 'Postcode',\n",
    "                      'All', 'All', 'All']\n",
    "measure = ['nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 ms, sys: 4.38 ms, total: 39.8 ms\n",
      "Wall time: 5.96 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blocking_results = pd.DataFrame(blocking_criterion, columns=['Blocking Criterion'])\n",
    "blocking_results['Measure'] = measure\n",
    "blocking_results['FEBRL Results (Mean of 10 Runs)'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blocking Criterion</th>\n",
       "      <th>Measure</th>\n",
       "      <th>FEBRL Results (Mean of 10 Runs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surname</td>\n",
       "      <td>nc</td>\n",
       "      <td>170843.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surname</td>\n",
       "      <td>pc</td>\n",
       "      <td>66.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surname</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.658280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given name</td>\n",
       "      <td>nc</td>\n",
       "      <td>154898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given name</td>\n",
       "      <td>pc</td>\n",
       "      <td>65.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Given name</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.690173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>nc</td>\n",
       "      <td>53197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>pc</td>\n",
       "      <td>84.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.893595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All</td>\n",
       "      <td>nc</td>\n",
       "      <td>372073.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>All</td>\n",
       "      <td>pc</td>\n",
       "      <td>97.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.255780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blocking Criterion Measure  FEBRL Results (Mean of 10 Runs)\n",
       "0             Surname      nc                    170843.000000\n",
       "1             Surname      pc                        66.500000\n",
       "2             Surname      rr                        99.658280\n",
       "3          Given name      nc                    154898.000000\n",
       "4          Given name      pc                        65.740000\n",
       "5          Given name      rr                        99.690173\n",
       "6            Postcode      nc                     53197.000000\n",
       "7            Postcode      pc                        84.380000\n",
       "8            Postcode      rr                        99.893595\n",
       "9                 All      nc                    372073.000000\n",
       "10                All      pc                        97.880000\n",
       "11                All      rr                        99.255780"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocking_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 FEBRL STD of blocking performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEBRL_surname_nc STD:  0.0\n",
      "FEBRL_surname_pc STD:  0.0\n",
      "FEBRL_surname_rr STD:  0.0\n",
      "FEBRL_given_name_nc STD:  0.0\n",
      "FEBRL_given_name_pc STD:  0.0\n",
      "FEBRL_given_name_rr STD:  0.0\n",
      "FEBRL_postcode_nc STD:  0.0\n",
      "FEBRL_postcode_pc STD:  0.0\n",
      "FEBRL_postcode_rr STD:  0.0\n",
      "FEBRL_all_nc STD:  0.0\n",
      "FEBRL_all_pc STD:  0.0\n",
      "FEBRL_all_rr STD:  0.0\n",
      "CPU times: user 10.6 ms, sys: 526 µs, total: 11.1 ms\n",
      "Wall time: 1.39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"FEBRL_surname_nc STD: \", statistics.pstdev(FEBRL_surname_nc)) \n",
    "print(\"FEBRL_surname_pc STD: \", statistics.pstdev(FEBRL_surname_pc)) \n",
    "print(\"FEBRL_surname_rr STD: \", statistics.pstdev(FEBRL_surname_rr)) \n",
    "print(\"FEBRL_given_name_nc STD: \", statistics.pstdev(FEBRL_given_name_nc)) \n",
    "print(\"FEBRL_given_name_pc STD: \", statistics.pstdev(FEBRL_given_name_pc)) \n",
    "print(\"FEBRL_given_name_rr STD: \", statistics.pstdev(FEBRL_given_name_rr)) \n",
    "print(\"FEBRL_postcode_nc STD: \", statistics.pstdev(FEBRL_postcode_nc)) \n",
    "print(\"FEBRL_postcode_pc STD: \", statistics.pstdev(FEBRL_postcode_pc)) \n",
    "print(\"FEBRL_postcode_rr STD: \", statistics.pstdev(FEBRL_postcode_rr)) \n",
    "print(\"FEBRL_all_nc STD: \", statistics.pstdev(FEBRL_all_nc)) \n",
    "print(\"FEBRL_all_pc STD: \", statistics.pstdev(FEBRL_all_pc))\n",
    "print(\"FEBRL_all_rr STD: \", statistics.pstdev(FEBRL_all_rr)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 FEBRL Results: Creating Paper’s Table 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 FEBRL Mean of classification performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 919 µs, sys: 5 µs, total: 924 µs\n",
      "Wall time: 118 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_col_MEAN = []\n",
    "pr_col_MEAN.append(sum(FEBRL_svm_pr) / float(len(FEBRL_svm_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_svm_bag_pr) / float(len(FEBRL_svm_bag_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_nn_pr) / float(len(FEBRL_nn_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_nn_bag_pr) / float(len(FEBRL_nn_bag_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_lr_pr) / float(len(FEBRL_lr_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_lr_bag_pr) / float(len(FEBRL_lr_bag_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_ensemble_pr) / float(len(FEBRL_ensemble_pr)))\n",
    "\n",
    "re_col_MEAN = []\n",
    "re_col_MEAN.append(sum(FEBRL_svm_re) / float(len(FEBRL_svm_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_svm_bag_re) / float(len(FEBRL_svm_bag_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_nn_re) / float(len(FEBRL_nn_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_nn_bag_re) / float(len(FEBRL_nn_bag_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_lr_re) / float(len(FEBRL_lr_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_lr_bag_re) / float(len(FEBRL_lr_bag_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_ensemble_re) / float(len(FEBRL_ensemble_re)))\n",
    "\n",
    "fs_col_MEAN = []\n",
    "fs_col_MEAN.append(sum(FEBRL_svm_fs) / float(len(FEBRL_svm_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_svm_bag_fs) / float(len(FEBRL_svm_bag_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_nn_fs) / float(len(FEBRL_nn_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_nn_bag_fs) / float(len(FEBRL_nn_bag_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_lr_fs) / float(len(FEBRL_lr_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_lr_bag_fs) / float(len(FEBRL_lr_bag_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_ensemble_fs) / float(len(FEBRL_ensemble_fs)))\n",
    "\n",
    "fc_col_MEAN = []\n",
    "fc_col_MEAN.append(sum(FEBRL_svm_fc) / float(len(FEBRL_svm_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_svm_bag_fc) / float(len(FEBRL_svm_bag_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_nn_fc) / float(len(FEBRL_nn_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_nn_bag_fc) / float(len(FEBRL_nn_bag_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_lr_fc) / float(len(FEBRL_lr_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_lr_bag_fc) / float(len(FEBRL_lr_bag_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_ensemble_fc) / float(len(FEBRL_ensemble_fc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 ms, sys: 590 µs, total: 20.9 ms\n",
      "Wall time: 2.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = ['SVM', 'SVM-bag', 'NN', 'NN-bag', 'LR', 'LR-bag', 'Stack+Bag']\n",
    "df_means = pd.DataFrame(models, columns=['Model'])\n",
    "df_means['pr(%)'] = pr_col_MEAN\n",
    "df_means['pr(%)'] = df_means['pr(%)']*100\n",
    "df_means['re(%)'] = re_col_MEAN\n",
    "df_means['re(%)'] = df_means['re(%)']*100\n",
    "df_means['fs(%)'] = fs_col_MEAN\n",
    "df_means['fs(%)'] = df_means['fs(%)']*100\n",
    "df_means['fc'] = fc_col_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>94.970645</td>\n",
       "      <td>99.683286</td>\n",
       "      <td>97.269678</td>\n",
       "      <td>273.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>96.263328</td>\n",
       "      <td>99.652636</td>\n",
       "      <td>97.928231</td>\n",
       "      <td>206.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>96.596002</td>\n",
       "      <td>99.650593</td>\n",
       "      <td>98.099327</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>96.967586</td>\n",
       "      <td>99.636289</td>\n",
       "      <td>98.283779</td>\n",
       "      <td>170.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>86.656968</td>\n",
       "      <td>99.822231</td>\n",
       "      <td>92.768180</td>\n",
       "      <td>762.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>87.628162</td>\n",
       "      <td>99.814058</td>\n",
       "      <td>93.318908</td>\n",
       "      <td>700.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>97.821222</td>\n",
       "      <td>99.609726</td>\n",
       "      <td>98.707265</td>\n",
       "      <td>127.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model      pr(%)      re(%)      fs(%)     fc\n",
       "0        SVM  94.970645  99.683286  97.269678  273.9\n",
       "1    SVM-bag  96.263328  99.652636  97.928231  206.4\n",
       "2         NN  96.596002  99.650593  98.099327  189.0\n",
       "3     NN-bag  96.967586  99.636289  98.283779  170.3\n",
       "4         LR  86.656968  99.822231  92.768180  762.5\n",
       "5     LR-bag  87.628162  99.814058  93.318908  700.2\n",
       "6  Stack+Bag  97.821222  99.609726  98.707265  127.7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 FEBRL STD of classification performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.8 ms, sys: 213 µs, total: 29 ms\n",
      "Wall time: 3.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_col_STD = []\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_svm_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_svm_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_nn_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_nn_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_lr_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_lr_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_ensemble_pr))\n",
    "\n",
    "re_col_STD = []\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_svm_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_svm_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_nn_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_nn_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_lr_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_lr_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_ensemble_re))\n",
    "\n",
    "fs_col_STD = []\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_svm_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_svm_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_nn_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_nn_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_lr_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_lr_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_ensemble_fs))\n",
    "\n",
    "fc_col_STD = []\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_svm_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_svm_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_nn_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_nn_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_lr_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_lr_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_ensemble_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 ms, sys: 592 µs, total: 20.3 ms\n",
      "Wall time: 2.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_STD = pd.DataFrame(models, columns=['Model'])\n",
    "df_STD['pr(%)'] = pr_col_STD\n",
    "df_STD['pr(%)'] = df_STD['pr(%)']*100\n",
    "df_STD['re(%)'] = re_col_STD\n",
    "df_STD['re(%)'] = df_STD['re(%)']*100\n",
    "df_STD['fs(%)'] = fs_col_STD\n",
    "df_STD['fs(%)'] = df_STD['fs(%)']*100\n",
    "df_STD['fc'] = fc_col_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.290977</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.149483</td>\n",
       "      <td>15.459625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>0.399282</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.204158</td>\n",
       "      <td>20.784610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.271229</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.138707</td>\n",
       "      <td>14.071247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>0.130552</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>0.065836</td>\n",
       "      <td>6.633250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>1.462529</td>\n",
       "      <td>0.030376</td>\n",
       "      <td>0.814931</td>\n",
       "      <td>91.318125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>1.403998</td>\n",
       "      <td>0.029540</td>\n",
       "      <td>0.776850</td>\n",
       "      <td>86.348133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>0.197872</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.097296</td>\n",
       "      <td>9.695360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model     pr(%)     re(%)     fs(%)         fc\n",
       "0        SVM  0.290977  0.013707  0.149483  15.459625\n",
       "1    SVM-bag  0.399282  0.009138  0.204158  20.784610\n",
       "2         NN  0.271229  0.006130  0.138707  14.071247\n",
       "3     NN-bag  0.130552  0.008173  0.065836   6.633250\n",
       "4         LR  1.462529  0.030376  0.814931  91.318125\n",
       "5     LR-bag  1.403998  0.029540  0.776850  86.348133\n",
       "6  Stack+Bag  0.197872  0.011004  0.097296   9.695360"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 FEBRL Comparing if the paper's results for classification performance fall within two standard deviations of the reproduced results after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 ms, sys: 903 µs, total: 38.8 ms\n",
      "Wall time: 4.83 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_lower_and_upper = pd.DataFrame(models, columns=['Model'])\n",
    "df_lower_and_upper['pr(%)_lower'] = df_means['pr(%)'] - 2 * df_STD['pr(%)']\n",
    "df_lower_and_upper['pr(%)_uppper'] = df_means['pr(%)'] + 2 * df_STD['pr(%)']    \n",
    "df_lower_and_upper['re(%)_lower'] = df_means['re(%)'] - 2 * df_STD['re(%)']\n",
    "df_lower_and_upper['re(%)_uppper'] = df_means['re(%)'] + 2 * df_STD['re(%)'] \n",
    "df_lower_and_upper['fs(%)_lower'] = df_means['fs(%)'] - 2 * df_STD['fs(%)']\n",
    "df_lower_and_upper['fs(%)_uppper'] = df_means['fs(%)'] + 2 * df_STD['fs(%)']\n",
    "df_lower_and_upper['fc_lower'] = df_means['fc'] - 2 * df_STD['fc']\n",
    "df_lower_and_upper['fc_uppper'] = df_means['fc'] + 2 * df_STD['fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)_lower</th>\n",
       "      <th>pr(%)_uppper</th>\n",
       "      <th>re(%)_lower</th>\n",
       "      <th>re(%)_uppper</th>\n",
       "      <th>fs(%)_lower</th>\n",
       "      <th>fs(%)_uppper</th>\n",
       "      <th>fc_lower</th>\n",
       "      <th>fc_uppper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>94.388691</td>\n",
       "      <td>95.552599</td>\n",
       "      <td>99.655872</td>\n",
       "      <td>99.710700</td>\n",
       "      <td>96.970712</td>\n",
       "      <td>97.568644</td>\n",
       "      <td>242.980750</td>\n",
       "      <td>304.819250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>95.464763</td>\n",
       "      <td>97.061892</td>\n",
       "      <td>99.634360</td>\n",
       "      <td>99.670912</td>\n",
       "      <td>97.519915</td>\n",
       "      <td>98.336548</td>\n",
       "      <td>164.830781</td>\n",
       "      <td>247.969219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>96.053544</td>\n",
       "      <td>97.138461</td>\n",
       "      <td>99.638333</td>\n",
       "      <td>99.662852</td>\n",
       "      <td>97.821914</td>\n",
       "      <td>98.376741</td>\n",
       "      <td>160.857505</td>\n",
       "      <td>217.142495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>96.706482</td>\n",
       "      <td>97.228691</td>\n",
       "      <td>99.619943</td>\n",
       "      <td>99.652636</td>\n",
       "      <td>98.152106</td>\n",
       "      <td>98.415451</td>\n",
       "      <td>157.033501</td>\n",
       "      <td>183.566499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>83.731910</td>\n",
       "      <td>89.582025</td>\n",
       "      <td>99.761479</td>\n",
       "      <td>99.882984</td>\n",
       "      <td>91.138317</td>\n",
       "      <td>94.398043</td>\n",
       "      <td>579.863749</td>\n",
       "      <td>945.136251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>84.820166</td>\n",
       "      <td>90.436157</td>\n",
       "      <td>99.754978</td>\n",
       "      <td>99.873138</td>\n",
       "      <td>91.765208</td>\n",
       "      <td>94.872607</td>\n",
       "      <td>527.503735</td>\n",
       "      <td>872.896265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>97.425478</td>\n",
       "      <td>98.216967</td>\n",
       "      <td>99.587719</td>\n",
       "      <td>99.631733</td>\n",
       "      <td>98.512674</td>\n",
       "      <td>98.901856</td>\n",
       "      <td>108.309281</td>\n",
       "      <td>147.090719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  pr(%)_lower  pr(%)_uppper  re(%)_lower  re(%)_uppper  \\\n",
       "0        SVM    94.388691     95.552599    99.655872     99.710700   \n",
       "1    SVM-bag    95.464763     97.061892    99.634360     99.670912   \n",
       "2         NN    96.053544     97.138461    99.638333     99.662852   \n",
       "3     NN-bag    96.706482     97.228691    99.619943     99.652636   \n",
       "4         LR    83.731910     89.582025    99.761479     99.882984   \n",
       "5     LR-bag    84.820166     90.436157    99.754978     99.873138   \n",
       "6  Stack+Bag    97.425478     98.216967    99.587719     99.631733   \n",
       "\n",
       "   fs(%)_lower  fs(%)_uppper    fc_lower   fc_uppper  \n",
       "0    96.970712     97.568644  242.980750  304.819250  \n",
       "1    97.519915     98.336548  164.830781  247.969219  \n",
       "2    97.821914     98.376741  160.857505  217.142495  \n",
       "3    98.152106     98.415451  157.033501  183.566499  \n",
       "4    91.138317     94.398043  579.863749  945.136251  \n",
       "5    91.765208     94.872607  527.503735  872.896265  \n",
       "6    98.512674     98.901856  108.309281  147.090719  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lower_and_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 ms, sys: 310 µs, total: 16.5 ms\n",
      "Wall time: 2.06 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_authors_values = pd.DataFrame(models, columns=['Model'])\n",
    "df_authors_values['pr(%)'] = [94.85, 95.46, 92.80, 92.75, 84.46, 84.27, 96.97]\n",
    "df_authors_values['re(%)'] = [99.73, 99.73, 99.59, 99.57, 99.69, 99.69, 99.43]\n",
    "df_authors_values['fs(%)'] = [97.23, 97.55, 96.08, 96.04, 91.44, 91.33, 98.18]\n",
    "df_authors_values['fc'] = [278, 245, 398, 402, 913, 926, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>94.85</td>\n",
       "      <td>99.73</td>\n",
       "      <td>97.23</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>95.46</td>\n",
       "      <td>99.73</td>\n",
       "      <td>97.55</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>92.80</td>\n",
       "      <td>99.59</td>\n",
       "      <td>96.08</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>92.75</td>\n",
       "      <td>99.57</td>\n",
       "      <td>96.04</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>84.46</td>\n",
       "      <td>99.69</td>\n",
       "      <td>91.44</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>84.27</td>\n",
       "      <td>99.69</td>\n",
       "      <td>91.33</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>96.97</td>\n",
       "      <td>99.43</td>\n",
       "      <td>98.18</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  pr(%)  re(%)  fs(%)   fc\n",
       "0        SVM  94.85  99.73  97.23  278\n",
       "1    SVM-bag  95.46  99.73  97.55  245\n",
       "2         NN  92.80  99.59  96.08  398\n",
       "3     NN-bag  92.75  99.57  96.04  402\n",
       "4         LR  84.46  99.69  91.44  913\n",
       "5     LR-bag  84.27  99.69  91.33  926\n",
       "6  Stack+Bag  96.97  99.43  98.18  180"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.6 ms, sys: 497 µs, total: 26.1 ms\n",
      "Wall time: 3.27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "within_2_std = pd.DataFrame(models, columns=['Model'])\n",
    "within_2_std['pr'] = (df_authors_values['pr(%)'] >= df_lower_and_upper['pr(%)_lower']) & (df_authors_values['pr(%)'] <= df_lower_and_upper['pr(%)_uppper'])\n",
    "within_2_std['re'] = (df_authors_values['re(%)'] >= df_lower_and_upper['re(%)_lower']) & (df_authors_values['re(%)'] <= df_lower_and_upper['re(%)_uppper'])\n",
    "within_2_std['fs'] = (df_authors_values['fs(%)'] >= df_lower_and_upper['fs(%)_lower']) & (df_authors_values['fs(%)'] <= df_lower_and_upper['fs(%)_uppper'])\n",
    "within_2_std['fc'] = (df_authors_values['fc'] >= df_lower_and_upper['fc_lower']) & (df_authors_values['fc'] <= df_lower_and_upper['fc_uppper'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr</th>\n",
       "      <th>re</th>\n",
       "      <th>fs</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model     pr     re     fs     fc\n",
       "0        SVM   True  False   True   True\n",
       "1    SVM-bag  False  False   True   True\n",
       "2         NN  False  False  False  False\n",
       "3     NN-bag  False  False  False  False\n",
       "4         LR   True  False   True   True\n",
       "5     LR-bag  False  False  False  False\n",
       "6  Stack+Bag  False  False  False  False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True = the paper results fall within 2 standard deviations of the mean according to the reproduce results\n",
    "# False = the paper results don't fall within 2 standard deviations of the mean according to the reproduce results\n",
    "within_2_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 ePBRN Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 1e+03 ns, total: 12 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def generate_true_links(df): \n",
    "    # although the match_id column is included in the original df to imply the true links,\n",
    "    # this function will create the true_link object identical to the true_links properties\n",
    "    # of recordlinkage toolkit, in order to exploit \"Compare.compute()\" from that toolkit\n",
    "    # in extract_function() for extracting features quicker.\n",
    "    # This process should be deprecated in the future release of the UNSW toolkit.\n",
    "    df[\"rec_id\"] = df.index.values.tolist()\n",
    "    indices_1 = []\n",
    "    indices_2 = []\n",
    "    processed = 0\n",
    "    for match_id in df[\"match_id\"].unique():\n",
    "        if match_id != -1:    \n",
    "            processed = processed + 1\n",
    "            # print(\"In routine generate_true_links(), count =\", processed)\n",
    "            # clear_output(wait=True)\n",
    "            linkages = df.loc[df['match_id'] == match_id]\n",
    "            for j in range(len(linkages)-1):\n",
    "                for k in range(j+1, len(linkages)):\n",
    "                    indices_1 = indices_1 + [linkages.iloc[j][\"rec_id\"]]\n",
    "                    indices_2 = indices_2 + [linkages.iloc[k][\"rec_id\"]]    \n",
    "    links = pd.MultiIndex.from_arrays([indices_1,indices_2])\n",
    "    return links\n",
    "\n",
    "def generate_false_links(df, size):\n",
    "    # A counterpart of generate_true_links(), with the purpose to generate random false pairs\n",
    "    # for training. The number of false pairs in specified as \"size\".\n",
    "    df[\"rec_id\"] = df.index.values.tolist()\n",
    "    indices_1 = []\n",
    "    indices_2 = []\n",
    "    unique_match_id = df[\"match_id\"].unique()\n",
    "    unique_match_id = unique_match_id[~np.isnan(unique_match_id)] # remove nan values\n",
    "    for j in range(size):\n",
    "            false_pair_ids = choice(unique_match_id, 2)\n",
    "            candidate_1_cluster = df.loc[df['match_id'] == false_pair_ids[0]]\n",
    "            candidate_1 = candidate_1_cluster.iloc[choice(range(len(candidate_1_cluster)))]\n",
    "            candidate_2_cluster = df.loc[df['match_id'] == false_pair_ids[1]]\n",
    "            candidate_2 = candidate_2_cluster.iloc[choice(range(len(candidate_2_cluster)))]    \n",
    "            indices_1 = indices_1 + [candidate_1[\"rec_id\"]]\n",
    "            indices_2 = indices_2 + [candidate_2[\"rec_id\"]]  \n",
    "    links = pd.MultiIndex.from_arrays([indices_1,indices_2])\n",
    "    return links\n",
    "\n",
    "def swap_fields_flag(f11, f12, f21, f22):\n",
    "    return ((f11 == f22) & (f12 == f21)).astype(float)\n",
    "\n",
    "def join_names_space(f11, f12, f21, f22):\n",
    "    return ((f11+\" \"+f12 == f21) | (f11+\" \"+f12 == f22)| (f21+\" \"+f22 == f11)| (f21+\" \"+f22 == f12)).astype(float)\n",
    "\n",
    "def join_names_dash(f11, f12, f21, f22):\n",
    "    return ((f11+\"-\"+f12 == f21) | (f11+\"-\"+f12 == f22)| (f21+\"-\"+f22 == f11)| (f21+\"-\"+f22 == f12)).astype(float)\n",
    "\n",
    "def abb_surname(f1, f2):\n",
    "    return ((f1[0]==f2) | (f1==f2[0])).astype(float)\n",
    "\n",
    "def reset_day(f11, f12, f21, f22):\n",
    "    return (((f11 == 1) & (f12 == 1))|((f21 == 1) & (f22 == 1))).astype(float)\n",
    "\n",
    "def extract_features(df, links):\n",
    "    c = rl.Compare()\n",
    "    c.string('given_name', 'given_name', method='levenshtein', label='y_name_leven')\n",
    "    c.string('surname', 'surname', method='levenshtein', label='y_surname_leven')  \n",
    "    c.string('given_name', 'given_name', method='jarowinkler', label='y_name_jaro')\n",
    "    c.string('surname', 'surname', method='jarowinkler', label='y_surname_jaro')  \n",
    "    c.string('postcode', 'postcode', method='jarowinkler', label='y_postcode')      \n",
    "    exact_fields = ['postcode', 'address_1', 'address_2', 'street_number']\n",
    "    for field in exact_fields:\n",
    "        c.exact(field, field, label='y_'+field+'_exact')\n",
    "    c.compare_vectorized(reset_day,('day', 'month'), ('day', 'month'),label='reset_day_flag')    \n",
    "    c.compare_vectorized(swap_fields_flag,('day', 'month'), ('day', 'month'),label='swap_day_month')    \n",
    "    c.compare_vectorized(swap_fields_flag,('surname', 'given_name'), ('surname', 'given_name'),label='swap_names')    \n",
    "    c.compare_vectorized(join_names_space,('surname', 'given_name'), ('surname', 'given_name'),label='join_names_space')\n",
    "    c.compare_vectorized(join_names_dash,('surname', 'given_name'), ('surname', 'given_name'),label='join_names_dash')\n",
    "    c.compare_vectorized(abb_surname,'surname', 'surname',label='abb_surname')\n",
    "    # Build features\n",
    "    feature_vectors = c.compute(links, df, df)\n",
    "    return feature_vectors\n",
    "\n",
    "def generate_train_X_y(df):\n",
    "    # This routine is to generate the feature vector X and the corresponding labels y\n",
    "    # with exactly equal number of samples for both classes to train the classifier.\n",
    "    pos = extract_features(df, train_true_links)\n",
    "    train_false_links = generate_false_links(df, len(train_true_links))    \n",
    "    neg = extract_features(df, train_false_links)\n",
    "    X = pos.values.tolist() + neg.values.tolist()\n",
    "    y = [1]*len(pos)+[0]*len(neg)\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def train_model(modeltype, modelparam, train_vectors, train_labels, modeltype_2):\n",
    "    if modeltype == 'svm': # Support Vector Machine\n",
    "        model = svm.SVC(C = modelparam, kernel = modeltype_2)\n",
    "        model.fit(train_vectors, train_labels) \n",
    "    elif modeltype == 'lg': # Logistic Regression\n",
    "        model = LogisticRegression(C=modelparam, penalty = modeltype_2,class_weight=None, dual=False, fit_intercept=True, \n",
    "                                   intercept_scaling=1, max_iter=5000, multi_class='ovr', \n",
    "                                   n_jobs=1, random_state=None)\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    elif modeltype == 'nb': # Naive Bayes\n",
    "        model = GaussianNB()\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    elif modeltype == 'nn': # Neural Network\n",
    "        model = MLPClassifier(solver='lbfgs', alpha=modelparam, hidden_layer_sizes=(256, ), \n",
    "                              activation = modeltype_2,random_state=None, batch_size='auto', \n",
    "                              learning_rate='constant',  learning_rate_init=0.001, \n",
    "                              power_t=0.5, max_iter=30000, shuffle=True, \n",
    "                              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                              nesterovs_momentum=True, early_stopping=False, \n",
    "                              validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    return model\n",
    "\n",
    "def classify(model, test_vectors):\n",
    "    result = model.predict(test_vectors)\n",
    "    return result\n",
    "\n",
    "    \n",
    "def evaluation(test_labels, result):\n",
    "    true_pos = np.logical_and(test_labels, result)\n",
    "    count_true_pos = np.sum(true_pos)\n",
    "    true_neg = np.logical_and(np.logical_not(test_labels),np.logical_not(result))\n",
    "    count_true_neg = np.sum(true_neg)\n",
    "    false_pos = np.logical_and(np.logical_not(test_labels), result)\n",
    "    count_false_pos = np.sum(false_pos)\n",
    "    false_neg = np.logical_and(test_labels,np.logical_not(result))\n",
    "    count_false_neg = np.sum(false_neg)\n",
    "    precision = count_true_pos/(count_true_pos+count_false_pos)\n",
    "    sensitivity = count_true_pos/(count_true_pos+count_false_neg) # sensitivity = recall\n",
    "    confusion_matrix = [count_true_pos, count_false_pos, count_false_neg, count_true_neg]\n",
    "    no_links_found = np.count_nonzero(result)\n",
    "    no_false = count_false_pos + count_false_neg\n",
    "    Fscore = 2*precision*sensitivity/(precision+sensitivity)\n",
    "    metrics_result = {'no_false':no_false, 'confusion_matrix':confusion_matrix ,'precision':precision,\n",
    "                     'sensitivity':sensitivity ,'no_links':no_links_found, 'F-score': Fscore}\n",
    "    return metrics_result\n",
    "\n",
    "def blocking_performance(candidates, true_links, df):\n",
    "    count = 0\n",
    "    for candi in candidates:\n",
    "        if df.loc[candi[0]][\"match_id\"]==df.loc[candi[1]][\"match_id\"]:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 ePBRN Running the Experiment 10 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ePBRN_surname_nc = []\n",
    "ePBRN_surname_pc = []\n",
    "ePBRN_surname_rr = []\n",
    "ePBRN_given_name_nc = []\n",
    "ePBRN_given_name_pc = []\n",
    "ePBRN_given_name_rr = []\n",
    "ePBRN_postcode_nc = []\n",
    "ePBRN_postcode_pc = []\n",
    "ePBRN_postcode_rr = []\n",
    "ePBRN_all_nc = []\n",
    "ePBRN_all_pc = []\n",
    "ePBRN_all_rr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ePBRN_svm_pr = []\n",
    "ePBRN_svm_re = []\n",
    "ePBRN_svm_fs = []\n",
    "ePBRN_svm_fc = []\n",
    "ePBRN_svm_bag_pr = []\n",
    "ePBRN_svm_bag_re = []\n",
    "ePBRN_svm_bag_fs = []\n",
    "ePBRN_svm_bag_fc = []\n",
    "ePBRN_nn_pr = []\n",
    "ePBRN_nn_re = []\n",
    "ePBRN_nn_fs = []\n",
    "ePBRN_nn_fc = []\n",
    "ePBRN_nn_bag_pr = []\n",
    "ePBRN_nn_bag_re = []\n",
    "ePBRN_nn_bag_fs = []\n",
    "ePBRN_nn_bag_fc = []\n",
    "ePBRN_lr_pr = []\n",
    "ePBRN_lr_re = []\n",
    "ePBRN_lr_fs = []\n",
    "ePBRN_lr_fc = []\n",
    "ePBRN_lr_bag_pr = []\n",
    "ePBRN_lr_bag_re = []\n",
    "ePBRN_lr_bag_fs = []\n",
    "ePBRN_lr_bag_fc = []\n",
    "ePBRN_ensemble_pr = []\n",
    "ePBRN_ensemble_re = []\n",
    "ePBRN_ensemble_fs = []\n",
    "ePBRN_ensemble_fc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ITERATION:  0\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  1\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  2\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  3\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  4\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  5\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  6\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  7\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  8\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  9\n",
      "\n",
      "Preparing the ePBRN dataset\n",
      "Import train set...\n",
      "Train set size: 14093 , number of matched pairs:  3212\n",
      "Finished building X_train, y_train\n",
      "ePBRN Blocking Results\n",
      "Test set size: 11743 , number of matched pairs:  2673\n",
      "ePBRN Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360949, 1: 2625})\n",
      "Finished building X_test, y_test\n",
      "CPU times: user 1h 45min 27s, sys: 2min 18s, total: 1h 47min 46s\n",
      "Wall time: 2h 22min\n",
      "Parser   : 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    print(\"\")\n",
    "    print(\"ITERATION: \", i)\n",
    "    print(\"\")\n",
    "\n",
    "    trainset = 'ePBRN_F_dup' \n",
    "    testset = 'ePBRN_D_dup'\n",
    "    \n",
    "    # 1. Preparing the ePBRN dataset #################################################################################\n",
    "    print(\"Preparing the ePBRN dataset\")\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    ## TRAIN SET CONSTRUCTION\n",
    "    # Import\n",
    "    print(\"Import train set...\")\n",
    "    df_train = pd.read_csv(\"Data_to_produce_ePBRN_dataset/\"+trainset+\".csv\", index_col = \"rec_id\")\n",
    "    train_true_links = generate_true_links(df_train)\n",
    "    print(\"Train set size:\", len(df_train), \", number of matched pairs: \", str(len(train_true_links)))\n",
    "\n",
    "    # Preprocess train set\n",
    "    df_train['postcode'] = df_train['postcode'].astype(str)\n",
    "\n",
    "    # Final train feature vectors and labels\n",
    "    X_train, y_train = generate_train_X_y(df_train)\n",
    "    print(\"Finished building X_train, y_train\")\n",
    "    \n",
    "    # 2. ePBRN Blocking Results ######################################################################################\n",
    "    print(\"ePBRN Blocking Results\")\n",
    "    '''\n",
    "    Modifying the code provided by the authors to produce the results in Table 4 of the paper. \n",
    "\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    # Blocking Criteria: declare non-match of all of the below fields disagree\n",
    "    # Import\n",
    "    ePBRN_blocking_results = []\n",
    "    df_test = pd.read_csv(\"Data_to_produce_ePBRN_dataset/\"+testset+\".csv\", index_col = \"rec_id\")\n",
    "    test_true_links = generate_true_links(df_test)\n",
    "    leng_test_true_links = len(test_true_links)\n",
    "    print(\"Test set size:\", len(df_test), \", number of matched pairs: \", str(leng_test_true_links))\n",
    "    \n",
    "    total_possible_pairs = comb(len(df_test),2)\n",
    "    match_pairs = leng_test_true_links\n",
    "\n",
    "    blocking_fields = [\"given_name\", \"surname\", \"postcode\"]\n",
    "    all_candidate_pairs = []\n",
    "    for field in blocking_fields:\n",
    "        block_indexer = rl.BlockIndex(on=field)\n",
    "        candidates = block_indexer.index(df_test)\n",
    "        detects = blocking_performance(candidates, test_true_links, df_test)\n",
    "        all_candidate_pairs = candidates.union(all_candidate_pairs)\n",
    "\n",
    "        # recording results for iteration\n",
    "        if field == 'given_name':\n",
    "            ePBRN_given_name_nc.append(len(candidates))\n",
    "            ePBRN_given_name_pc.append(detects/match_pairs*100.0)\n",
    "            ePBRN_given_name_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)\n",
    "        if field == 'surname':\n",
    "            ePBRN_surname_nc.append(len(candidates))\n",
    "            ePBRN_surname_pc.append(detects/match_pairs*100.0)\n",
    "            ePBRN_surname_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)\n",
    "        if field == 'postcode':\n",
    "            ePBRN_postcode_nc.append(len(candidates))\n",
    "            ePBRN_postcode_pc.append(detects/match_pairs*100.0)\n",
    "            ePBRN_postcode_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)\n",
    "\n",
    "    detects = blocking_performance(all_candidate_pairs, test_true_links, df_test)\n",
    "    \n",
    "    ePBRN_all_nc.append(len(all_candidate_pairs))\n",
    "    ePBRN_all_pc.append(detects/match_pairs*100.0)\n",
    "    ePBRN_all_rr.append((1-(len(all_candidate_pairs)/1.0/total_possible_pairs))*100)\n",
    "   \n",
    "    # 3. ePBRN Classification Performance Results ####################################################################\n",
    "    print(\"ePBRN Classification Performance Results\")\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    ## TEST SET CONSTRUCTION\n",
    "\n",
    "    # Preprocess test set\n",
    "    print(\"Processing test set...\")\n",
    "    print(\"Preprocess...\")\n",
    "    df_test['postcode'] = df_test['postcode'].astype(str)\n",
    "\n",
    "    # Test feature vectors and labels construction\n",
    "    print(\"Extract feature vectors...\")\n",
    "    df_X_test = extract_features(df_test, all_candidate_pairs)\n",
    "    vectors = df_X_test.values.tolist()\n",
    "    labels = [0]*len(vectors)\n",
    "    feature_index = df_X_test.index\n",
    "    for i in range(0, len(feature_index)):\n",
    "        if df_test.loc[feature_index[i][0]][\"match_id\"]==df_test.loc[feature_index[i][1]][\"match_id\"]:\n",
    "            labels[i] = 1\n",
    "    X_test, y_test = shuffle(vectors, labels, random_state=0)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    print(\"Count labels of y_test:\",collections.Counter(y_test))\n",
    "    print(\"Finished building X_test, y_test\")\n",
    "    \n",
    "    # 3.1 SVM BASE LEARNERS CLASSIFICATION AND EVALUATION ############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for SVM on the ePBRN dataset\n",
    "    1. RBF kernel\n",
    "    2. C = 0.001\n",
    "    '''\n",
    "    modeltype = 'svm' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'rbf'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 0.001\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false  = final_eval['no_false']\n",
    "    \n",
    "    ePBRN_svm_pr.append(precision)\n",
    "    ePBRN_svm_re.append(sensitivity)\n",
    "    ePBRN_svm_fs.append(Fscore)\n",
    "    ePBRN_svm_fc.append(nb_false)\n",
    "\n",
    "    # 3.2 NN BASE LEARNERS CLASSIFICATION AND EVALUATION #############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for NN on the ePBRN dataset\n",
    "    1. ReLu activation with a = 2000\n",
    "    '''\n",
    "    modeltype = 'nn' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'relu'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 2000\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false = final_eval['no_false']\n",
    "\n",
    "    ePBRN_nn_pr.append(precision)\n",
    "    ePBRN_nn_re.append(sensitivity)\n",
    "    ePBRN_nn_fs.append(Fscore)\n",
    "    ePBRN_nn_fc.append(nb_false)\n",
    "\n",
    "    # 3.3 LR BASE LEARNERS CLASSIFICATION AND EVALUATION #############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for NN on the ePBRN dataset\n",
    "    1. Regularization I2\n",
    "    2. C = 0.005\n",
    "    '''\n",
    "    modeltype = 'lg' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'l2'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 0.005\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false = final_eval['no_false']\n",
    "    \n",
    "    ePBRN_lr_pr.append(precision)\n",
    "    ePBRN_lr_re.append(sensitivity)\n",
    "    ePBRN_lr_fs.append(Fscore)\n",
    "    ePBRN_lr_fc.append(nb_false)\n",
    "    \n",
    "    # 3.4 BAGGING BASE LEARNERS CLASSIFICATION AND EVALUATION ########################################################\n",
    "    modeltypes = ['svm', 'nn', 'lg'] \n",
    "    modeltypes_2 = ['rbf', 'relu', 'l2']\n",
    "    modelparams = [0.001, 2000, 0.005]\n",
    "    nFold = 10\n",
    "    kf = KFold(n_splits=nFold)\n",
    "    model_raw_score = [0]*3\n",
    "    model_binary_score = [0]*3\n",
    "    model_i = 0\n",
    "    for model_i in range(3):\n",
    "        modeltype = modeltypes[model_i]\n",
    "        modeltype_2 = modeltypes_2[model_i]\n",
    "        modelparam = modelparams[model_i]\n",
    "        iFold = 0\n",
    "        result_fold = [0]*nFold\n",
    "        final_eval_fold = [0]*nFold\n",
    "        for train_index, valid_index in kf.split(X_train):\n",
    "            X_train_fold = X_train[train_index]\n",
    "            y_train_fold = y_train[train_index]\n",
    "            md =  train_model(modeltype, modelparam, X_train_fold, y_train_fold, modeltype_2)\n",
    "            result_fold[iFold] = classify(md, X_test)\n",
    "            final_eval_fold[iFold] = evaluation(y_test, result_fold[iFold])\n",
    "            iFold = iFold + 1\n",
    "        bagging_raw_score = np.average(result_fold, axis=0)\n",
    "        bagging_binary_score  = np.copy(bagging_raw_score)\n",
    "        bagging_binary_score[bagging_binary_score > 0.5] = 1\n",
    "        bagging_binary_score[bagging_binary_score <= 0.5] = 0\n",
    "        bagging_eval = evaluation(y_test, bagging_binary_score)\n",
    "\n",
    "        if modeltype == 'svm':\n",
    "            ePBRN_svm_bag_pr.append(bagging_eval['precision'])\n",
    "            ePBRN_svm_bag_re.append(bagging_eval['sensitivity'])\n",
    "            ePBRN_svm_bag_fs.append(bagging_eval['F-score'])\n",
    "            ePBRN_svm_bag_fc.append(bagging_eval['no_false'])\n",
    "        elif modeltype == 'nn':\n",
    "            ePBRN_nn_bag_pr.append(bagging_eval['precision'])\n",
    "            ePBRN_nn_bag_re.append(bagging_eval['sensitivity'])\n",
    "            ePBRN_nn_bag_fs.append(bagging_eval['F-score'])\n",
    "            ePBRN_nn_bag_fc.append(bagging_eval['no_false'])   \n",
    "        elif modeltype == 'lg':\n",
    "            ePBRN_lr_bag_pr.append(bagging_eval['precision'])\n",
    "            ePBRN_lr_bag_re.append(bagging_eval['sensitivity'])\n",
    "            ePBRN_lr_bag_fs.append(bagging_eval['F-score'])\n",
    "            ePBRN_lr_bag_fc.append(bagging_eval['no_false'])\n",
    "\n",
    "        model_raw_score[model_i] = bagging_raw_score\n",
    "        model_binary_score[model_i] = bagging_binary_score\n",
    "        \n",
    "    # 4 Ensemble Model Performance ###################################################################################\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    thres = .99\n",
    "    stack_raw_score = np.average(model_raw_score, axis=0)\n",
    "    stack_binary_score = np.copy(stack_raw_score)\n",
    "    stack_binary_score[stack_binary_score > thres] = 1\n",
    "    stack_binary_score[stack_binary_score <= thres] = 0\n",
    "    stacking_eval = evaluation(y_test, stack_binary_score)\n",
    "    \n",
    "    ePBRN_ensemble_pr.append(stacking_eval['precision'])\n",
    "    ePBRN_ensemble_re.append(stacking_eval['sensitivity'])\n",
    "    ePBRN_ensemble_fs.append(stacking_eval['F-score'])\n",
    "    ePBRN_ensemble_fc.append(stacking_eval['no_false'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 ePBRN Results: Creating Paper’s Table 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 ePBRN Mean of blocking performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 186 µs, sys: 5 µs, total: 191 µs\n",
      "Wall time: 27.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "results.append(sum(ePBRN_surname_nc) / float(len(ePBRN_surname_nc)))\n",
    "results.append(sum(ePBRN_surname_pc) / float(len(ePBRN_surname_pc)))\n",
    "results.append(sum(ePBRN_surname_rr) / float(len(ePBRN_surname_rr)))\n",
    "results.append(sum(ePBRN_given_name_nc) / float(len(ePBRN_given_name_nc)))\n",
    "results.append(sum(ePBRN_given_name_pc) / float(len(ePBRN_given_name_pc)))\n",
    "results.append(sum(ePBRN_given_name_rr) / float(len(ePBRN_given_name_rr)))\n",
    "results.append(sum(ePBRN_postcode_nc) / float(len(ePBRN_postcode_nc)))\n",
    "results.append(sum(ePBRN_postcode_pc) / float(len(ePBRN_postcode_pc)))\n",
    "results.append(sum(ePBRN_postcode_rr) / float(len(ePBRN_postcode_rr)))\n",
    "results.append(sum(ePBRN_all_nc) / float(len(ePBRN_all_nc)))\n",
    "results.append(sum(ePBRN_all_pc) / float(len(ePBRN_all_pc)))\n",
    "results.append(sum(ePBRN_all_rr) / float(len(ePBRN_all_rr)))\n",
    "\n",
    "blocking_criterion = ['Surname', 'Surname', 'Surname', \n",
    "                      'Given name', 'Given name', 'Given name',\n",
    "                      'Postcode', 'Postcode', 'Postcode',\n",
    "                      'All', 'All', 'All']\n",
    "measure = ['nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.96 ms, sys: 464 µs, total: 5.43 ms\n",
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blocking_results = pd.DataFrame(blocking_criterion, columns=['Blocking Criterion'])\n",
    "blocking_results['Measure'] = measure\n",
    "blocking_results['ePBRN Results (Mean of 10 Runs)'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blocking Criterion</th>\n",
       "      <th>Measure</th>\n",
       "      <th>ePBRN Results (Mean of 10 Runs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surname</td>\n",
       "      <td>nc</td>\n",
       "      <td>32785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surname</td>\n",
       "      <td>pc</td>\n",
       "      <td>55.592967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surname</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.952446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given name</td>\n",
       "      <td>nc</td>\n",
       "      <td>254696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given name</td>\n",
       "      <td>pc</td>\n",
       "      <td>59.221848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Given name</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.630571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>nc</td>\n",
       "      <td>79556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>pc</td>\n",
       "      <td>94.051627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.884606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All</td>\n",
       "      <td>nc</td>\n",
       "      <td>363574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>All</td>\n",
       "      <td>pc</td>\n",
       "      <td>98.204265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.472647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blocking Criterion Measure  ePBRN Results (Mean of 10 Runs)\n",
       "0             Surname      nc                     32785.000000\n",
       "1             Surname      pc                        55.592967\n",
       "2             Surname      rr                        99.952446\n",
       "3          Given name      nc                    254696.000000\n",
       "4          Given name      pc                        59.221848\n",
       "5          Given name      rr                        99.630571\n",
       "6            Postcode      nc                     79556.000000\n",
       "7            Postcode      pc                        94.051627\n",
       "8            Postcode      rr                        99.884606\n",
       "9                 All      nc                    363574.000000\n",
       "10                All      pc                        98.204265\n",
       "11                All      rr                        99.472647"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocking_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 ePBRN STD of blocking performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ePBRN_surname_nc STD:  0.0\n",
      "ePBRN_surname_pc STD:  0.0\n",
      "ePBRN_surname_rr STD:  0.0\n",
      "ePBRN_given_name_nc STD:  0.0\n",
      "ePBRN_given_name_pc STD:  0.0\n",
      "ePBRN_given_name_rr STD:  0.0\n",
      "ePBRN_postcode_nc STD:  0.0\n",
      "ePBRN_postcode_pc STD:  0.0\n",
      "ePBRN_postcode_rr STD:  0.0\n",
      "ePBRN_all_nc STD:  0.0\n",
      "ePBRN_all_pc STD:  0.0\n",
      "ePBRN_all_rr STD:  0.0\n",
      "CPU times: user 14.1 ms, sys: 1.88 ms, total: 16 ms\n",
      "Wall time: 2.24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"ePBRN_surname_nc STD: \", statistics.pstdev(ePBRN_surname_nc)) \n",
    "print(\"ePBRN_surname_pc STD: \", statistics.pstdev(ePBRN_surname_pc)) \n",
    "print(\"ePBRN_surname_rr STD: \", statistics.pstdev(ePBRN_surname_rr)) \n",
    "print(\"ePBRN_given_name_nc STD: \", statistics.pstdev(ePBRN_given_name_nc)) \n",
    "print(\"ePBRN_given_name_pc STD: \", statistics.pstdev(ePBRN_given_name_pc)) \n",
    "print(\"ePBRN_given_name_rr STD: \", statistics.pstdev(ePBRN_given_name_rr)) \n",
    "print(\"ePBRN_postcode_nc STD: \", statistics.pstdev(ePBRN_postcode_nc)) \n",
    "print(\"ePBRN_postcode_pc STD: \", statistics.pstdev(ePBRN_postcode_pc)) \n",
    "print(\"ePBRN_postcode_rr STD: \", statistics.pstdev(ePBRN_postcode_rr)) \n",
    "print(\"ePBRN_all_nc STD: \", statistics.pstdev(ePBRN_all_nc)) \n",
    "print(\"ePBRN_all_pc STD: \", statistics.pstdev(ePBRN_all_pc))\n",
    "print(\"ePBRN_all_rr STD: \", statistics.pstdev(ePBRN_all_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0 ePBRN Results: Creating Paper’s Table 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 ePBRN Mean of classification performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 ms, sys: 44 µs, total: 1.61 ms\n",
      "Wall time: 209 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_col_MEAN = []\n",
    "pr_col_MEAN.append(sum(ePBRN_svm_pr) / float(len(ePBRN_svm_pr)))\n",
    "pr_col_MEAN.append(sum(ePBRN_svm_bag_pr) / float(len(ePBRN_svm_bag_pr)))\n",
    "pr_col_MEAN.append(sum(ePBRN_nn_pr) / float(len(ePBRN_nn_pr)))\n",
    "pr_col_MEAN.append(sum(ePBRN_nn_bag_pr) / float(len(ePBRN_nn_bag_pr)))\n",
    "pr_col_MEAN.append(sum(ePBRN_lr_pr) / float(len(ePBRN_lr_pr)))\n",
    "pr_col_MEAN.append(sum(ePBRN_lr_bag_pr) / float(len(ePBRN_lr_bag_pr)))\n",
    "pr_col_MEAN.append(sum(ePBRN_ensemble_pr) / float(len(ePBRN_ensemble_pr)))\n",
    "\n",
    "re_col_MEAN = []\n",
    "re_col_MEAN.append(sum(ePBRN_svm_re) / float(len(ePBRN_svm_re)))\n",
    "re_col_MEAN.append(sum(ePBRN_svm_bag_re) / float(len(ePBRN_svm_bag_re)))\n",
    "re_col_MEAN.append(sum(ePBRN_nn_re) / float(len(ePBRN_nn_re)))\n",
    "re_col_MEAN.append(sum(ePBRN_nn_bag_re) / float(len(ePBRN_nn_bag_re)))\n",
    "re_col_MEAN.append(sum(ePBRN_lr_re) / float(len(ePBRN_lr_re)))\n",
    "re_col_MEAN.append(sum(ePBRN_lr_bag_re) / float(len(ePBRN_lr_bag_re)))\n",
    "re_col_MEAN.append(sum(ePBRN_ensemble_re) / float(len(ePBRN_ensemble_re)))\n",
    "\n",
    "fs_col_MEAN = []\n",
    "fs_col_MEAN.append(sum(ePBRN_svm_fs) / float(len(ePBRN_svm_fs)))\n",
    "fs_col_MEAN.append(sum(ePBRN_svm_bag_fs) / float(len(ePBRN_svm_bag_fs)))\n",
    "fs_col_MEAN.append(sum(ePBRN_nn_fs) / float(len(ePBRN_nn_fs)))\n",
    "fs_col_MEAN.append(sum(ePBRN_nn_bag_fs) / float(len(ePBRN_nn_bag_fs)))\n",
    "fs_col_MEAN.append(sum(ePBRN_lr_fs) / float(len(ePBRN_lr_fs)))\n",
    "fs_col_MEAN.append(sum(ePBRN_lr_bag_fs) / float(len(ePBRN_lr_bag_fs)))\n",
    "fs_col_MEAN.append(sum(ePBRN_ensemble_fs) / float(len(ePBRN_ensemble_fs)))\n",
    "\n",
    "fc_col_MEAN = []\n",
    "fc_col_MEAN.append(sum(ePBRN_svm_fc) / float(len(ePBRN_svm_fc)))\n",
    "fc_col_MEAN.append(sum(ePBRN_svm_bag_fc) / float(len(ePBRN_svm_bag_fc)))\n",
    "fc_col_MEAN.append(sum(ePBRN_nn_fc) / float(len(ePBRN_nn_fc)))\n",
    "fc_col_MEAN.append(sum(ePBRN_nn_bag_fc) / float(len(ePBRN_nn_bag_fc)))\n",
    "fc_col_MEAN.append(sum(ePBRN_lr_fc) / float(len(ePBRN_lr_fc)))\n",
    "fc_col_MEAN.append(sum(ePBRN_lr_bag_fc) / float(len(ePBRN_lr_bag_fc)))\n",
    "fc_col_MEAN.append(sum(ePBRN_ensemble_fc) / float(len(ePBRN_ensemble_fc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 ms, sys: 1.28 ms, total: 25.2 ms\n",
      "Wall time: 3.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = ['SVM', 'SVM-bag', 'NN', 'NN-bag', 'LR', 'LR-bag', 'Stack+Bag']\n",
    "df_means = pd.DataFrame(models, columns=['Model'])\n",
    "df_means['pr(%)'] = pr_col_MEAN\n",
    "df_means['pr(%)'] = df_means['pr(%)']*100\n",
    "df_means['re(%)'] = re_col_MEAN\n",
    "df_means['re(%)'] = df_means['re(%)']*100\n",
    "df_means['fs(%)'] = fs_col_MEAN\n",
    "df_means['fs(%)'] = df_means['fs(%)']*100\n",
    "df_means['fc'] = fc_col_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>33.962085</td>\n",
       "      <td>99.226667</td>\n",
       "      <td>50.598924</td>\n",
       "      <td>5089.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>38.986579</td>\n",
       "      <td>98.998095</td>\n",
       "      <td>55.936975</td>\n",
       "      <td>4096.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>69.698121</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>81.229126</td>\n",
       "      <td>1180.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>70.777419</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>81.957394</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>59.677290</td>\n",
       "      <td>97.600000</td>\n",
       "      <td>74.066237</td>\n",
       "      <td>1794.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>60.345107</td>\n",
       "      <td>97.592381</td>\n",
       "      <td>74.575984</td>\n",
       "      <td>1746.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>73.925839</td>\n",
       "      <td>97.287619</td>\n",
       "      <td>84.012545</td>\n",
       "      <td>972.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model      pr(%)      re(%)      fs(%)      fc\n",
       "0        SVM  33.962085  99.226667  50.598924  5089.2\n",
       "1    SVM-bag  38.986579  98.998095  55.936975  4096.4\n",
       "2         NN  69.698121  97.333333  81.229126  1180.9\n",
       "3     NN-bag  70.777419  97.333333  81.957394  1125.0\n",
       "4         LR  59.677290  97.600000  74.066237  1794.2\n",
       "5     LR-bag  60.345107  97.592381  74.575984  1746.8\n",
       "6  Stack+Bag  73.925839  97.287619  84.012545   972.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 ePBRN STD of classification performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.6 ms, sys: 1.01 ms, total: 38.6 ms\n",
      "Wall time: 4.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_col_STD = []\n",
    "pr_col_STD.append(statistics.pstdev(ePBRN_svm_pr))\n",
    "pr_col_STD.append(statistics.pstdev(ePBRN_svm_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(ePBRN_nn_pr))\n",
    "pr_col_STD.append(statistics.pstdev(ePBRN_nn_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(ePBRN_lr_pr))\n",
    "pr_col_STD.append(statistics.pstdev(ePBRN_lr_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(ePBRN_ensemble_pr))\n",
    "\n",
    "re_col_STD = []\n",
    "re_col_STD.append(statistics.pstdev(ePBRN_svm_re))\n",
    "re_col_STD.append(statistics.pstdev(ePBRN_svm_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(ePBRN_nn_re))\n",
    "re_col_STD.append(statistics.pstdev(ePBRN_nn_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(ePBRN_lr_re))\n",
    "re_col_STD.append(statistics.pstdev(ePBRN_lr_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(ePBRN_ensemble_re))\n",
    "\n",
    "fs_col_STD = []\n",
    "fs_col_STD.append(statistics.pstdev(ePBRN_svm_fs))\n",
    "fs_col_STD.append(statistics.pstdev(ePBRN_svm_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(ePBRN_nn_fs))\n",
    "fs_col_STD.append(statistics.pstdev(ePBRN_nn_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(ePBRN_lr_fs))\n",
    "fs_col_STD.append(statistics.pstdev(ePBRN_lr_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(ePBRN_ensemble_fs))\n",
    "\n",
    "fc_col_STD = []\n",
    "fc_col_STD.append(statistics.pstdev(ePBRN_svm_fc))\n",
    "fc_col_STD.append(statistics.pstdev(ePBRN_svm_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(ePBRN_nn_fc))\n",
    "fc_col_STD.append(statistics.pstdev(ePBRN_nn_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(ePBRN_lr_fc))\n",
    "fc_col_STD.append(statistics.pstdev(ePBRN_lr_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(ePBRN_ensemble_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 ms, sys: 1.07 ms, total: 24.1 ms\n",
      "Wall time: 3.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_STD = pd.DataFrame(models, columns=['Model'])\n",
    "df_STD['pr(%)'] = pr_col_STD\n",
    "df_STD['pr(%)'] = df_STD['pr(%)']*100\n",
    "df_STD['re(%)'] = re_col_STD\n",
    "df_STD['re(%)'] = df_STD['re(%)']*100\n",
    "df_STD['fs(%)'] = fs_col_STD\n",
    "df_STD['fs(%)'] = df_STD['fs(%)']*100\n",
    "df_STD['fc'] = fc_col_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.778565</td>\n",
       "      <td>0.017457</td>\n",
       "      <td>0.870004</td>\n",
       "      <td>181.402867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>0.843877</td>\n",
       "      <td>0.038285</td>\n",
       "      <td>0.866809</td>\n",
       "      <td>145.526630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.347078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235776</td>\n",
       "      <td>18.248288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>0.356078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238962</td>\n",
       "      <td>18.193405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.301553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232245</td>\n",
       "      <td>21.679483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.267191</td>\n",
       "      <td>24.839485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>0.296642</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.188759</td>\n",
       "      <td>13.747727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model     pr(%)     re(%)     fs(%)          fc\n",
       "0        SVM  0.778565  0.017457  0.870004  181.402867\n",
       "1    SVM-bag  0.843877  0.038285  0.866809  145.526630\n",
       "2         NN  0.347078  0.000000  0.235776   18.248288\n",
       "3     NN-bag  0.356078  0.000000  0.238962   18.193405\n",
       "4         LR  0.301553  0.000000  0.232245   21.679483\n",
       "5     LR-bag  0.355789  0.022857  0.267191   24.839485\n",
       "6  Stack+Bag  0.296642  0.015238  0.188759   13.747727"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 ePBRN Comparing if the paper's results for classification performance fall within two standard deviations of the reproduced results after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.5 ms, sys: 2.65 ms, total: 59.2 ms\n",
      "Wall time: 7.48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_lower_and_upper = pd.DataFrame(models, columns=['Model'])\n",
    "df_lower_and_upper['pr(%)_lower'] = df_means['pr(%)'] - 2 * df_STD['pr(%)']\n",
    "df_lower_and_upper['pr(%)_uppper'] = df_means['pr(%)'] + 2 * df_STD['pr(%)']    \n",
    "df_lower_and_upper['re(%)_lower'] = df_means['re(%)'] - 2 * df_STD['re(%)']\n",
    "df_lower_and_upper['re(%)_uppper'] = df_means['re(%)'] + 2 * df_STD['re(%)'] \n",
    "df_lower_and_upper['fs(%)_lower'] = df_means['fs(%)'] - 2 * df_STD['fs(%)']\n",
    "df_lower_and_upper['fs(%)_uppper'] = df_means['fs(%)'] + 2 * df_STD['fs(%)']\n",
    "df_lower_and_upper['fc_lower'] = df_means['fc'] - 2 * df_STD['fc']\n",
    "df_lower_and_upper['fc_uppper'] = df_means['fc'] + 2 * df_STD['fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)_lower</th>\n",
       "      <th>pr(%)_uppper</th>\n",
       "      <th>re(%)_lower</th>\n",
       "      <th>re(%)_uppper</th>\n",
       "      <th>fs(%)_lower</th>\n",
       "      <th>fs(%)_uppper</th>\n",
       "      <th>fc_lower</th>\n",
       "      <th>fc_uppper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>32.404955</td>\n",
       "      <td>35.519216</td>\n",
       "      <td>99.191752</td>\n",
       "      <td>99.261582</td>\n",
       "      <td>48.858915</td>\n",
       "      <td>52.338932</td>\n",
       "      <td>4726.394267</td>\n",
       "      <td>5452.005733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>37.298825</td>\n",
       "      <td>40.674332</td>\n",
       "      <td>98.921525</td>\n",
       "      <td>99.074666</td>\n",
       "      <td>54.203358</td>\n",
       "      <td>57.670593</td>\n",
       "      <td>3805.346740</td>\n",
       "      <td>4387.453260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>69.003964</td>\n",
       "      <td>70.392277</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>80.757574</td>\n",
       "      <td>81.700677</td>\n",
       "      <td>1144.403425</td>\n",
       "      <td>1217.396575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>70.065264</td>\n",
       "      <td>71.489574</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>81.479470</td>\n",
       "      <td>82.435318</td>\n",
       "      <td>1088.613189</td>\n",
       "      <td>1161.386811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>59.074184</td>\n",
       "      <td>60.280396</td>\n",
       "      <td>97.600000</td>\n",
       "      <td>97.600000</td>\n",
       "      <td>73.601746</td>\n",
       "      <td>74.530727</td>\n",
       "      <td>1750.841033</td>\n",
       "      <td>1837.558967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>59.633529</td>\n",
       "      <td>61.056686</td>\n",
       "      <td>97.546667</td>\n",
       "      <td>97.638095</td>\n",
       "      <td>74.041602</td>\n",
       "      <td>75.110366</td>\n",
       "      <td>1697.121031</td>\n",
       "      <td>1796.478969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>73.332555</td>\n",
       "      <td>74.519122</td>\n",
       "      <td>97.257143</td>\n",
       "      <td>97.318095</td>\n",
       "      <td>83.635027</td>\n",
       "      <td>84.390064</td>\n",
       "      <td>944.504546</td>\n",
       "      <td>999.495454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  pr(%)_lower  pr(%)_uppper  re(%)_lower  re(%)_uppper  \\\n",
       "0        SVM    32.404955     35.519216    99.191752     99.261582   \n",
       "1    SVM-bag    37.298825     40.674332    98.921525     99.074666   \n",
       "2         NN    69.003964     70.392277    97.333333     97.333333   \n",
       "3     NN-bag    70.065264     71.489574    97.333333     97.333333   \n",
       "4         LR    59.074184     60.280396    97.600000     97.600000   \n",
       "5     LR-bag    59.633529     61.056686    97.546667     97.638095   \n",
       "6  Stack+Bag    73.332555     74.519122    97.257143     97.318095   \n",
       "\n",
       "   fs(%)_lower  fs(%)_uppper     fc_lower    fc_uppper  \n",
       "0    48.858915     52.338932  4726.394267  5452.005733  \n",
       "1    54.203358     57.670593  3805.346740  4387.453260  \n",
       "2    80.757574     81.700677  1144.403425  1217.396575  \n",
       "3    81.479470     82.435318  1088.613189  1161.386811  \n",
       "4    73.601746     74.530727  1750.841033  1837.558967  \n",
       "5    74.041602     75.110366  1697.121031  1796.478969  \n",
       "6    83.635027     84.390064   944.504546   999.495454  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lower_and_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 ms, sys: 1.69 ms, total: 21.1 ms\n",
      "Wall time: 2.89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_authors_values = pd.DataFrame(models, columns=['Model'])\n",
    "df_authors_values['pr(%)'] = [94.85, 95.46, 92.80, 92.75, 84.46, 84.27, 96.97]\n",
    "df_authors_values['re(%)'] = [99.73, 99.73, 99.59, 99.57, 99.69, 99.69, 99.43]\n",
    "df_authors_values['fs(%)'] = [97.23, 97.55, 96.08, 96.04, 91.44, 91.33, 98.18]\n",
    "df_authors_values['fc'] = [278, 245, 398, 402, 913, 926, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>94.85</td>\n",
       "      <td>99.73</td>\n",
       "      <td>97.23</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>95.46</td>\n",
       "      <td>99.73</td>\n",
       "      <td>97.55</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>92.80</td>\n",
       "      <td>99.59</td>\n",
       "      <td>96.08</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>92.75</td>\n",
       "      <td>99.57</td>\n",
       "      <td>96.04</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>84.46</td>\n",
       "      <td>99.69</td>\n",
       "      <td>91.44</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>84.27</td>\n",
       "      <td>99.69</td>\n",
       "      <td>91.33</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>96.97</td>\n",
       "      <td>99.43</td>\n",
       "      <td>98.18</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  pr(%)  re(%)  fs(%)   fc\n",
       "0        SVM  94.85  99.73  97.23  278\n",
       "1    SVM-bag  95.46  99.73  97.55  245\n",
       "2         NN  92.80  99.59  96.08  398\n",
       "3     NN-bag  92.75  99.57  96.04  402\n",
       "4         LR  84.46  99.69  91.44  913\n",
       "5     LR-bag  84.27  99.69  91.33  926\n",
       "6  Stack+Bag  96.97  99.43  98.18  180"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 ms, sys: 505 µs, total: 4.7 ms\n",
      "Wall time: 4.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "within_2_std = pd.DataFrame(models, columns=['Model'])\n",
    "within_2_std['pr'] = (df_authors_values['pr(%)'] >= df_lower_and_upper['pr(%)_lower']) & (df_authors_values['pr(%)'] <= df_lower_and_upper['pr(%)_uppper'])\n",
    "within_2_std['re'] = (df_authors_values['re(%)'] >= df_lower_and_upper['re(%)_lower']) & (df_authors_values['re(%)'] <= df_lower_and_upper['re(%)_uppper'])\n",
    "within_2_std['fs'] = (df_authors_values['fs(%)'] >= df_lower_and_upper['fs(%)_lower']) & (df_authors_values['fs(%)'] <= df_lower_and_upper['fs(%)_uppper'])\n",
    "within_2_std['fc'] = (df_authors_values['fc'] >= df_lower_and_upper['fc_lower']) & (df_authors_values['fc'] <= df_lower_and_upper['fc_uppper'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr</th>\n",
       "      <th>re</th>\n",
       "      <th>fs</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model     pr     re     fs     fc\n",
       "0        SVM  False  False  False  False\n",
       "1    SVM-bag  False  False  False  False\n",
       "2         NN  False  False  False  False\n",
       "3     NN-bag  False  False  False  False\n",
       "4         LR  False  False  False  False\n",
       "5     LR-bag  False  False  False  False\n",
       "6  Stack+Bag  False  False  False  False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True = the paper results fall within 2 standard deviations of the mean according to the reproduce results\n",
    "# False = the paper results don't fall within 2 standard deviations of the mean according to the reproduce results\n",
    "within_2_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
