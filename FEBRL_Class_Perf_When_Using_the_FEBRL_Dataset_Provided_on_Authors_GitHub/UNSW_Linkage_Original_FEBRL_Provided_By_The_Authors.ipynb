{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source of Code:\n",
    "This code reproduces the results of the “Statistical supervised meta-ensemble algorithm for medical record linkage” paper. The vast majority of this code was sourced from the original paper’s GitHub repository. The original code has been slightly modified and amended. Specifically, the author's code has been amended to run the experiment 10 times. The mean and standard deviation of the 10 results were recorded.\n",
    "\n",
    "K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "\n",
    "# Source of Dataset:\n",
    "The FEBRL datasets used in this experiment trial was sourced directly from the author's GitHub repository https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/. Specifically the febrl3_UNSW_provided_by_authors.csv file is the febrl3_UNSW.csv file on the authors' GitHub site. Similarly, the febrl4_UNSW_provided_by_authors.csv file is the febrl4_UNSW.csv file on the authors' GitHub site. \n",
    "\n",
    "The reason why the  febrl3_UNSW_provided_by_authors.csv and  febrl4_UNSW_provided_by_authors.csv datasets were used in this experiment instead of regenerating the FEBRL dataset with the code provided by the authors' is because the FEBRL dataset is generated using the Python Record Linkage Toolkit library. As a result, the generated dataset is dependent on the version of Python Record Linkage Toolkit library at the time. The current version of the generated dataset is slightly different than the FEBRL datasets published on the authors' GitHub site. When consulting with Jitendra Jonnagaddala, one of the paper's authors, it was stated that a reasonable explanation for this observed difference between the dataset published on the authors' GitHub and the current regeneration of the dataset using the Python Record Linkage Toolkit library was due to changes in the library. The paper was published in 2019 and the most recent change to the library was committed on April 19, 2022. https://github.com/J535D165/recordlinkage\n",
    "\n",
    "It is expected that different datasets will led to different results. Thus to help eliminate this factor of variation in the results when attempting to reproduce the study, the febrl3_UNSW_provided_by_authors.csv and  febrl4_UNSW_provided_by_authors.csv datasets were used.  These datasets were published on the authors' GitHub and are likely to be the most similar to the datasets used in the original study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 169 ms, total: 1.42 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Source: \n",
    "K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "'''\n",
    "import recordlinkage as rl, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from recordlinkage.preprocessing import phonetic\n",
    "from numpy.random import choice\n",
    "import collections, numpy\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from math import comb\n",
    "import statistics\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Source: \n",
    "K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "'''\n",
    "def generate_true_links(df): \n",
    "    # although the match_id column is included in the original df to imply the true links,\n",
    "    # this function will create the true_link object identical to the true_links properties\n",
    "    # of recordlinkage toolkit, in order to exploit \"Compare.compute()\" from that toolkit\n",
    "    # in extract_function() for extracting features quicker.\n",
    "    # This process should be deprecated in the future release of the UNSW toolkit.\n",
    "    df[\"rec_id\"] = df.index.values.tolist()\n",
    "    indices_1 = []\n",
    "    indices_2 = []\n",
    "    processed = 0\n",
    "    for match_id in df[\"match_id\"].unique():\n",
    "        if match_id != -1:    \n",
    "            processed = processed + 1\n",
    "            # print(\"In routine generate_true_links(), count =\", processed)\n",
    "            # clear_output(wait=True)\n",
    "            linkages = df.loc[df['match_id'] == match_id]\n",
    "            for j in range(len(linkages)-1):\n",
    "                for k in range(j+1, len(linkages)):\n",
    "                    indices_1 = indices_1 + [linkages.iloc[j][\"rec_id\"]]\n",
    "                    indices_2 = indices_2 + [linkages.iloc[k][\"rec_id\"]]    \n",
    "    links = pd.MultiIndex.from_arrays([indices_1,indices_2])\n",
    "    return links\n",
    "\n",
    "def generate_false_links(df, size):\n",
    "    # A counterpart of generate_true_links(), with the purpose to generate random false pairs\n",
    "    # for training. The number of false pairs in specified as \"size\".\n",
    "    df[\"rec_id\"] = df.index.values.tolist()\n",
    "    indices_1 = []\n",
    "    indices_2 = []\n",
    "    unique_match_id = df[\"match_id\"].unique()\n",
    "    for j in range(size):\n",
    "            false_pair_ids = choice(unique_match_id, 2)\n",
    "            candidate_1_cluster = df.loc[df['match_id'] == false_pair_ids[0]]\n",
    "            candidate_1 = candidate_1_cluster.iloc[choice(range(len(candidate_1_cluster)))]\n",
    "            candidate_2_cluster = df.loc[df['match_id'] == false_pair_ids[1]]\n",
    "            candidate_2 = candidate_2_cluster.iloc[choice(range(len(candidate_2_cluster)))]    \n",
    "            indices_1 = indices_1 + [candidate_1[\"rec_id\"]]\n",
    "            indices_2 = indices_2 + [candidate_2[\"rec_id\"]]  \n",
    "    links = pd.MultiIndex.from_arrays([indices_1,indices_2])\n",
    "    return links\n",
    "\n",
    "def swap_fields_flag(f11, f12, f21, f22):\n",
    "    return int((f11 == f22) and (f12 == f21))\n",
    "\n",
    "def extract_features(df, links):\n",
    "    c = rl.Compare()\n",
    "    c.string('given_name', 'given_name', method='jarowinkler', label='y_name')\n",
    "    c.string('given_name_soundex', 'given_name_soundex', method='jarowinkler', label='y_name_soundex')\n",
    "    c.string('given_name_nysiis', 'given_name_nysiis', method='jarowinkler', label='y_name_nysiis')\n",
    "    c.string('surname', 'surname', method='jarowinkler', label='y_surname')\n",
    "    c.string('surname_soundex', 'surname_soundex', method='jarowinkler', label='y_surname_soundex')\n",
    "    c.string('surname_nysiis', 'surname_nysiis', method='jarowinkler', label='y_surname_nysiis')\n",
    "    c.exact('street_number', 'street_number', label='y_street_number')\n",
    "    c.string('address_1', 'address_1', method='levenshtein', threshold=0.7, label='y_address1')\n",
    "    c.string('address_2', 'address_2', method='levenshtein', threshold=0.7, label='y_address2')\n",
    "    c.exact('postcode', 'postcode', label='y_postcode')\n",
    "    c.exact('day', 'day', label='y_day')\n",
    "    c.exact('month', 'month', label='y_month')\n",
    "    c.exact('year', 'year', label='y_year')\n",
    "        \n",
    "    # Build features\n",
    "    feature_vectors = c.compute(links, df, df)\n",
    "    return feature_vectors\n",
    "\n",
    "def generate_train_X_y(df):\n",
    "    # This routine is to generate the feature vector X and the corresponding labels y\n",
    "    # with exactly equal number of samples for both classes to train the classifier.\n",
    "    pos = extract_features(df, train_true_links)\n",
    "    train_false_links = generate_false_links(df, len(train_true_links))    \n",
    "    neg = extract_features(df, train_false_links)\n",
    "    X = pos.values.tolist() + neg.values.tolist()\n",
    "    y = [1]*len(pos)+[0]*len(neg)\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def train_model(modeltype, modelparam, train_vectors, train_labels, modeltype_2):\n",
    "    if modeltype == 'svm': # Support Vector Machine\n",
    "        model = svm.SVC(C = modelparam, kernel = modeltype_2)\n",
    "        model.fit(train_vectors, train_labels) \n",
    "    elif modeltype == 'lg': # Logistic Regression\n",
    "        model = LogisticRegression(C=modelparam, penalty = modeltype_2,class_weight=None, dual=False, fit_intercept=True, \n",
    "                                   intercept_scaling=1, max_iter=5000, multi_class='ovr', \n",
    "                                   n_jobs=1, random_state=None)\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    elif modeltype == 'nb': # Naive Bayes\n",
    "        model = GaussianNB()\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    elif modeltype == 'nn': # Neural Network\n",
    "        model = MLPClassifier(solver='lbfgs', alpha=modelparam, hidden_layer_sizes=(256, ), \n",
    "                              activation = modeltype_2,random_state=None, batch_size='auto', \n",
    "                              learning_rate='constant',  learning_rate_init=0.001, \n",
    "                              power_t=0.5, max_iter=10000, shuffle=True, \n",
    "                              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                              nesterovs_momentum=True, early_stopping=False, \n",
    "                              validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        model.fit(train_vectors, train_labels)\n",
    "    return model\n",
    "\n",
    "def classify(model, test_vectors):\n",
    "    result = model.predict(test_vectors)\n",
    "    return result\n",
    "\n",
    "    \n",
    "def evaluation(test_labels, result):\n",
    "    true_pos = np.logical_and(test_labels, result)\n",
    "    count_true_pos = np.sum(true_pos)\n",
    "    true_neg = np.logical_and(np.logical_not(test_labels),np.logical_not(result))\n",
    "    count_true_neg = np.sum(true_neg)\n",
    "    false_pos = np.logical_and(np.logical_not(test_labels), result)\n",
    "    count_false_pos = np.sum(false_pos)\n",
    "    false_neg = np.logical_and(test_labels,np.logical_not(result))\n",
    "    count_false_neg = np.sum(false_neg)\n",
    "    precision = count_true_pos/(count_true_pos+count_false_pos)\n",
    "    sensitivity = count_true_pos/(count_true_pos+count_false_neg) # sensitivity = recall\n",
    "    confusion_matrix = [count_true_pos, count_false_pos, count_false_neg, count_true_neg]\n",
    "    no_links_found = np.count_nonzero(result)\n",
    "    no_false = count_false_pos + count_false_neg\n",
    "    Fscore = 2*precision*sensitivity/(precision+sensitivity)\n",
    "    metrics_result = {'no_false':no_false, 'confusion_matrix':confusion_matrix ,'precision':precision,\n",
    "                     'sensitivity':sensitivity ,'no_links':no_links_found, 'F-score': Fscore}\n",
    "    return metrics_result\n",
    "\n",
    "def blocking_performance(candidates, true_links, df):\n",
    "    count = 0\n",
    "    for candi in candidates:\n",
    "        if df.loc[candi[0]][\"match_id\"]==df.loc[candi[1]][\"match_id\"]:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Running the Experiment 10 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FEBRL_surname_nc = []\n",
    "FEBRL_surname_pc = []\n",
    "FEBRL_surname_rr = []\n",
    "FEBRL_given_name_nc = []\n",
    "FEBRL_given_name_pc = []\n",
    "FEBRL_given_name_rr = []\n",
    "FEBRL_postcode_nc = []\n",
    "FEBRL_postcode_pc = []\n",
    "FEBRL_postcode_rr = []\n",
    "FEBRL_all_nc = []\n",
    "FEBRL_all_pc = []\n",
    "FEBRL_all_rr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FEBRL_svm_pr = []\n",
    "FEBRL_svm_re = []\n",
    "FEBRL_svm_fs = []\n",
    "FEBRL_svm_fc = []\n",
    "FEBRL_svm_bag_pr = []\n",
    "FEBRL_svm_bag_re = []\n",
    "FEBRL_svm_bag_fs = []\n",
    "FEBRL_svm_bag_fc = []\n",
    "FEBRL_nn_pr = []\n",
    "FEBRL_nn_re = []\n",
    "FEBRL_nn_fs = []\n",
    "FEBRL_nn_fc = []\n",
    "FEBRL_nn_bag_pr = []\n",
    "FEBRL_nn_bag_re = []\n",
    "FEBRL_nn_bag_fs = []\n",
    "FEBRL_nn_bag_fc = []\n",
    "FEBRL_lr_pr = []\n",
    "FEBRL_lr_re = []\n",
    "FEBRL_lr_fs = []\n",
    "FEBRL_lr_fc = []\n",
    "FEBRL_lr_bag_pr = []\n",
    "FEBRL_lr_bag_re = []\n",
    "FEBRL_lr_bag_fs = []\n",
    "FEBRL_lr_bag_fc = []\n",
    "FEBRL_ensemble_pr = []\n",
    "FEBRL_ensemble_re = []\n",
    "FEBRL_ensemble_fs = []\n",
    "FEBRL_ensemble_fc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ITERATION:  0\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  1\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  2\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  3\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  4\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  5\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  6\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  7\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  8\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "\n",
      "ITERATION:  9\n",
      "\n",
      "Preparing the FEBRL dataset\n",
      "Import train set...\n",
      "Train set size: 10000 , number of matched pairs:  5000\n",
      "Finished building X_train, y_train\n",
      "FEBRL Blocking Results\n",
      "Import test set...\n",
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n",
      "FEBRL Classification Performance Results\n",
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n",
      "CPU times: user 1h 6min 10s, sys: 1min 52s, total: 1h 8min 2s\n",
      "Wall time: 51min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    print(\"\")\n",
    "    print(\"ITERATION: \", i)\n",
    "    print(\"\")\n",
    "\n",
    "    trainset = 'febrl4_UNSW_provided_by_authors'\n",
    "    testset = 'febrl4_UNSW_provided_by_authors'\n",
    "    \n",
    "    # 1. Preparing the FEBRL dataset #################################################################################\n",
    "    print(\"Preparing the FEBRL dataset\")\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    # Import\n",
    "    print(\"Import train set...\")\n",
    "    df_train = pd.read_csv(trainset+\".csv\", index_col = \"rec_id\")\n",
    "    train_true_links = generate_true_links(df_train)\n",
    "    print(\"Train set size:\", len(df_train), \", number of matched pairs: \", str(len(train_true_links)))\n",
    "\n",
    "    # Preprocess train set\n",
    "    df_train['postcode'] = df_train['postcode'].astype(str)\n",
    "    df_train['given_name_soundex'] = phonetic(df_train['given_name'], method='soundex')\n",
    "    df_train['given_name_nysiis'] = phonetic(df_train['given_name'], method='nysiis')\n",
    "    df_train['surname_soundex'] = phonetic(df_train['surname'], method='soundex')\n",
    "    df_train['surname_nysiis'] = phonetic(df_train['surname'], method='nysiis')\n",
    "\n",
    "    # Final train feature vectors and labels\n",
    "    X_train, y_train = generate_train_X_y(df_train)\n",
    "    print(\"Finished building X_train, y_train\")\n",
    "    \n",
    "    # 2. FEBRL Blocking Results ######################################################################################\n",
    "    print(\"FEBRL Blocking Results\")\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "\n",
    "    Code has been modified to reproduce and print Table 4 of the paper.\n",
    "    '''\n",
    "    # Blocking Criteria: declare non-match of all of the below fields disagree\n",
    "    # Import\n",
    "    print(\"Import test set...\")\n",
    "    FEBRL_blocking_results = []\n",
    "    df_test = pd.read_csv(testset+\".csv\", index_col = \"rec_id\")\n",
    "    test_true_links = generate_true_links(df_test)\n",
    "    leng_test_true_links = len(test_true_links)\n",
    "    print(\"Test set size:\", len(df_test), \", number of matched pairs: \", str(leng_test_true_links))\n",
    "\n",
    "    total_possible_pairs = comb(len(df_test),2)\n",
    "    match_pairs = leng_test_true_links\n",
    "\n",
    "    print(\"BLOCKING PERFORMANCE:\")\n",
    "    blocking_fields = [\"given_name\", \"surname\", \"postcode\"]\n",
    "    all_candidate_pairs = []\n",
    "    for field in blocking_fields:\n",
    "        block_indexer = rl.BlockIndex(on=field)\n",
    "        candidates = block_indexer.index(df_test)\n",
    "        detects = blocking_performance(candidates, test_true_links, df_test)\n",
    "        all_candidate_pairs = candidates.union(all_candidate_pairs)\n",
    "        print(\"Number of pairs of matched \"+ field +\": \"+str(len(candidates)), \", detected \",\n",
    "             detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "              str(leng_test_true_links-detects) )\n",
    "        \n",
    "        # recording results for iteration\n",
    "        if field == 'given_name':\n",
    "            FEBRL_given_name_nc.append(len(candidates))\n",
    "            FEBRL_given_name_pc.append(detects/match_pairs*100.0)\n",
    "            FEBRL_given_name_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)\n",
    "        if field == 'surname':\n",
    "            FEBRL_surname_nc.append(len(candidates))\n",
    "            FEBRL_surname_pc.append(detects/match_pairs*100.0)\n",
    "            FEBRL_surname_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)\n",
    "        if field == 'postcode':\n",
    "            FEBRL_postcode_nc.append(len(candidates))\n",
    "            FEBRL_postcode_pc.append(detects/match_pairs*100.0)\n",
    "            FEBRL_postcode_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)  \n",
    "\n",
    "    detects = blocking_performance(all_candidate_pairs, test_true_links, df_test)\n",
    "    print(\"Number of pairs of at least 1 field matched: \" + str(len(all_candidate_pairs)), \", detected \",\n",
    "         detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "              str(leng_test_true_links-detects) )\n",
    "    \n",
    "    # recording results for iteration\n",
    "    FEBRL_all_nc.append(len(all_candidate_pairs))\n",
    "    FEBRL_all_pc.append(detects/match_pairs*100.0)\n",
    "    FEBRL_all_rr.append((1-(len(candidates)/1.0/total_possible_pairs))*100)\n",
    "    \n",
    "    # 3. FEBRL Classification Performance Results ####################################################################\n",
    "    print(\"FEBRL Classification Performance Results\")\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    ## TEST SET CONSTRUCTION\n",
    "    # Preprocess test set\n",
    "    print(\"Processing test set...\")\n",
    "    print(\"Preprocess...\")\n",
    "    df_test['postcode'] = df_test['postcode'].astype(str)\n",
    "    df_test['given_name_soundex'] = phonetic(df_test['given_name'], method='soundex')\n",
    "    df_test['given_name_nysiis'] = phonetic(df_test['given_name'], method='nysiis')\n",
    "    df_test['surname_soundex'] = phonetic(df_test['surname'], method='soundex')\n",
    "    df_test['surname_nysiis'] = phonetic(df_test['surname'], method='nysiis')\n",
    "\n",
    "    # Test feature vectors and labels construction\n",
    "    print(\"Extract feature vectors...\")\n",
    "    df_X_test = extract_features(df_test, all_candidate_pairs)\n",
    "    vectors = df_X_test.values.tolist()\n",
    "    labels = [0]*len(vectors)\n",
    "    feature_index = df_X_test.index\n",
    "    for i in range(0, len(feature_index)):\n",
    "        if df_test.loc[feature_index[i][0]][\"match_id\"]==df_test.loc[feature_index[i][1]][\"match_id\"]:\n",
    "            labels[i] = 1\n",
    "    X_test, y_test = shuffle(vectors, labels, random_state=0)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    print(\"Count labels of y_test:\",collections.Counter(y_test))\n",
    "    print(\"Finished building X_test, y_test\")\n",
    "\n",
    "    '''\n",
    "    Modifying the code provided by the authors to produce the results in Table 6 of the paper. \n",
    "    Used the hyperparameters as specified by Table 5 of the paper to build the models.\n",
    "\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    # 3.1 SVM BASE LEARNERS CLASSIFICATION AND EVALUATION ############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for SVM on the FEBRL dataset\n",
    "    1. Linear kernel\n",
    "    2. C = 0.005\n",
    "    '''\n",
    "    modeltype = 'svm' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'linear'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 0.005\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false  = final_eval['no_false']\n",
    "    \n",
    "    FEBRL_svm_pr.append(precision)\n",
    "    FEBRL_svm_re.append(sensitivity)\n",
    "    FEBRL_svm_fs.append(Fscore)\n",
    "    FEBRL_svm_fc.append(nb_false)\n",
    "\n",
    "    # 3.2 NN BASE LEARNERS CLASSIFICATION AND EVALUATION #############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for NN on the FEBRL dataset\n",
    "    1. ReLu activation with a = 100\n",
    "    '''\n",
    "    modeltype = 'nn' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'relu'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 100\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false = final_eval['no_false']\n",
    "    \n",
    "    FEBRL_nn_pr.append(precision)\n",
    "    FEBRL_nn_re.append(sensitivity)\n",
    "    FEBRL_nn_fs.append(Fscore)\n",
    "    FEBRL_nn_fc.append(nb_false)\n",
    "\n",
    "    # 3.3 LR BASE LEARNERS CLASSIFICATION AND EVALUATION #############################################################\n",
    "    '''\n",
    "    Table 5 Hyperparameters for NN on the FEBRL dataset\n",
    "    1. Regularization I2\n",
    "    2. C = 0.2\n",
    "    '''\n",
    "    modeltype = 'lg' # choose between 'svm', 'lg', 'nn'\n",
    "    modeltype_2 = 'l2'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "    modelparam = 0.2\n",
    "\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision = final_eval['precision']\n",
    "    sensitivity = final_eval['sensitivity']\n",
    "    Fscore = final_eval['F-score']\n",
    "    nb_false = final_eval['no_false']\n",
    "    \n",
    "    FEBRL_lr_pr.append(precision)\n",
    "    FEBRL_lr_re.append(sensitivity)\n",
    "    FEBRL_lr_fs.append(Fscore)\n",
    "    FEBRL_lr_fc.append(nb_false)\n",
    "    \n",
    "    # 3.4 BAGGING BASE LEARNERS CLASSIFICATION AND EVALUATION ########################################################\n",
    "    modeltypes = ['svm', 'nn', 'lg'] \n",
    "    modeltypes_2 = ['linear', 'relu', 'l2']\n",
    "    modelparams = [0.005, 100, 0.2]\n",
    "    nFold = 10\n",
    "    kf = KFold(n_splits=nFold)\n",
    "    model_raw_score = [0]*3\n",
    "    model_binary_score = [0]*3\n",
    "    model_i = 0\n",
    "    for model_i in range(3):\n",
    "        modeltype = modeltypes[model_i]\n",
    "        modeltype_2 = modeltypes_2[model_i]\n",
    "        modelparam = modelparams[model_i]\n",
    "        # print(modeltype, \"per fold:\")\n",
    "        iFold = 0\n",
    "        result_fold = [0]*nFold\n",
    "        final_eval_fold = [0]*nFold\n",
    "        for train_index, valid_index in kf.split(X_train):\n",
    "            X_train_fold = X_train[train_index]\n",
    "            y_train_fold = y_train[train_index]\n",
    "            md =  train_model(modeltype, modelparam, X_train_fold, y_train_fold, modeltype_2)\n",
    "            result_fold[iFold] = classify(md, X_test)\n",
    "            final_eval_fold[iFold] = evaluation(y_test, result_fold[iFold])\n",
    "            # print(\"Fold\", str(iFold), final_eval_fold[iFold])\n",
    "            iFold = iFold + 1\n",
    "        bagging_raw_score = np.average(result_fold, axis=0)\n",
    "        bagging_binary_score  = np.copy(bagging_raw_score)\n",
    "        bagging_binary_score[bagging_binary_score > 0.5] = 1\n",
    "        bagging_binary_score[bagging_binary_score <= 0.5] = 0\n",
    "        bagging_eval = evaluation(y_test, bagging_binary_score)\n",
    "        # print(modeltype, \"bagging:\", bagging_eval)\n",
    "        # print('')\n",
    "\n",
    "        if modeltype == 'svm':\n",
    "            FEBRL_svm_bag_pr.append(bagging_eval['precision'])\n",
    "            FEBRL_svm_bag_re.append(bagging_eval['sensitivity'])\n",
    "            FEBRL_svm_bag_fs.append(bagging_eval['F-score'])\n",
    "            FEBRL_svm_bag_fc.append(bagging_eval['no_false'])\n",
    "        elif modeltype == 'nn':\n",
    "            FEBRL_nn_bag_pr.append(bagging_eval['precision'])\n",
    "            FEBRL_nn_bag_re.append(bagging_eval['sensitivity'])\n",
    "            FEBRL_nn_bag_fs.append(bagging_eval['F-score'])\n",
    "            FEBRL_nn_bag_fc.append(bagging_eval['no_false'])   \n",
    "        elif modeltype == 'lg':\n",
    "            FEBRL_lr_bag_pr.append(bagging_eval['precision'])\n",
    "            FEBRL_lr_bag_re.append(bagging_eval['sensitivity'])\n",
    "            FEBRL_lr_bag_fs.append(bagging_eval['F-score'])\n",
    "            FEBRL_lr_bag_fc.append(bagging_eval['no_false'])\n",
    "\n",
    "        model_raw_score[model_i] = bagging_raw_score\n",
    "        model_binary_score[model_i] = bagging_binary_score\n",
    "        \n",
    "    # 4 Ensemble Model Performance ###################################################################################\n",
    "    '''\n",
    "    Source: \n",
    "    K. Vo, J. Jonnagaddala and S.-T. Liaw, \"Medical-Record-Linkage-Ensemble,\" 16 February 2019. [Online]. \n",
    "    Available: https://github.com/ePBRN/Medical-Record-Linkage-Ensemble/.\n",
    "    '''\n",
    "    thres = .99\n",
    "\n",
    "    stack_raw_score = np.average(model_raw_score, axis=0)\n",
    "    stack_binary_score = np.copy(stack_raw_score)\n",
    "    stack_binary_score[stack_binary_score > thres] = 1\n",
    "    stack_binary_score[stack_binary_score <= thres] = 0\n",
    "    stacking_eval = evaluation(y_test, stack_binary_score)\n",
    "    \n",
    "    FEBRL_ensemble_pr.append(stacking_eval['precision'])\n",
    "    FEBRL_ensemble_re.append(stacking_eval['sensitivity'])\n",
    "    FEBRL_ensemble_fs.append(stacking_eval['F-score'])\n",
    "    FEBRL_ensemble_fc.append(stacking_eval['no_false'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Results: Creating the Paper’s Table 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Mean of blocking performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 µs, sys: 4 µs, total: 24 µs\n",
      "Wall time: 25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "results.append(sum(FEBRL_surname_nc) / float(len(FEBRL_surname_nc)))\n",
    "results.append(sum(FEBRL_surname_pc) / float(len(FEBRL_surname_pc)))\n",
    "results.append(sum(FEBRL_surname_rr) / float(len(FEBRL_surname_rr)))\n",
    "results.append(sum(FEBRL_given_name_nc) / float(len(FEBRL_given_name_nc)))\n",
    "results.append(sum(FEBRL_given_name_pc) / float(len(FEBRL_given_name_pc)))\n",
    "results.append(sum(FEBRL_given_name_rr) / float(len(FEBRL_given_name_rr)))\n",
    "results.append(sum(FEBRL_postcode_nc) / float(len(FEBRL_postcode_nc)))\n",
    "results.append(sum(FEBRL_postcode_pc) / float(len(FEBRL_postcode_pc)))\n",
    "results.append(sum(FEBRL_postcode_rr) / float(len(FEBRL_postcode_rr)))\n",
    "results.append(sum(FEBRL_all_nc) / float(len(FEBRL_all_nc)))\n",
    "results.append(sum(FEBRL_all_pc) / float(len(FEBRL_all_pc)))\n",
    "results.append(sum(FEBRL_all_rr) / float(len(FEBRL_all_rr)))\n",
    "\n",
    "blocking_criterion = ['Surname', 'Surname', 'Surname', \n",
    "                      'Given name', 'Given name', 'Given name',\n",
    "                      'Postcode', 'Postcode', 'Postcode',\n",
    "                      'All', 'All', 'All']\n",
    "measure = ['nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr',\n",
    "           'nc', 'pc', 'rr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.5 ms, sys: 3.24 ms, total: 43.7 ms\n",
      "Wall time: 5.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blocking_results = pd.DataFrame(blocking_criterion, columns=['Blocking Criterion'])\n",
    "blocking_results['Measure'] = measure\n",
    "blocking_results['FEBRL Results (Mean of 10 Runs)'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blocking Criterion</th>\n",
       "      <th>Measure</th>\n",
       "      <th>FEBRL Results (Mean of 10 Runs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surname</td>\n",
       "      <td>nc</td>\n",
       "      <td>170843.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surname</td>\n",
       "      <td>pc</td>\n",
       "      <td>66.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surname</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.658280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given name</td>\n",
       "      <td>nc</td>\n",
       "      <td>154898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given name</td>\n",
       "      <td>pc</td>\n",
       "      <td>65.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Given name</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.690173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>nc</td>\n",
       "      <td>53197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>pc</td>\n",
       "      <td>84.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Postcode</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.893595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All</td>\n",
       "      <td>nc</td>\n",
       "      <td>372073.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>All</td>\n",
       "      <td>pc</td>\n",
       "      <td>97.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All</td>\n",
       "      <td>rr</td>\n",
       "      <td>99.893595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blocking Criterion Measure  FEBRL Results (Mean of 10 Runs)\n",
       "0             Surname      nc                    170843.000000\n",
       "1             Surname      pc                        66.500000\n",
       "2             Surname      rr                        99.658280\n",
       "3          Given name      nc                    154898.000000\n",
       "4          Given name      pc                        65.740000\n",
       "5          Given name      rr                        99.690173\n",
       "6            Postcode      nc                     53197.000000\n",
       "7            Postcode      pc                        84.380000\n",
       "8            Postcode      rr                        99.893595\n",
       "9                 All      nc                    372073.000000\n",
       "10                All      pc                        97.880000\n",
       "11                All      rr                        99.893595"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocking_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 STD of blocking performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEBRL_surname_nc STD:  0.0\n",
      "FEBRL_surname_pc STD:  0.0\n",
      "FEBRL_surname_rr STD:  0.0\n",
      "FEBRL_given_name_nc STD:  0.0\n",
      "FEBRL_given_name_pc STD:  0.0\n",
      "FEBRL_given_name_rr STD:  0.0\n",
      "FEBRL_postcode_nc STD:  0.0\n",
      "FEBRL_postcode_pc STD:  0.0\n",
      "FEBRL_postcode_rr STD:  0.0\n",
      "FEBRL_all_nc STD:  0.0\n",
      "FEBRL_all_pc STD:  0.0\n",
      "FEBRL_all_rr STD:  0.0\n",
      "CPU times: user 13 ms, sys: 621 µs, total: 13.7 ms\n",
      "Wall time: 1.69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"FEBRL_surname_nc STD: \", statistics.pstdev(FEBRL_surname_nc)) \n",
    "print(\"FEBRL_surname_pc STD: \", statistics.pstdev(FEBRL_surname_pc)) \n",
    "print(\"FEBRL_surname_rr STD: \", statistics.pstdev(FEBRL_surname_rr)) \n",
    "print(\"FEBRL_given_name_nc STD: \", statistics.pstdev(FEBRL_given_name_nc)) \n",
    "print(\"FEBRL_given_name_pc STD: \", statistics.pstdev(FEBRL_given_name_pc)) \n",
    "print(\"FEBRL_given_name_rr STD: \", statistics.pstdev(FEBRL_given_name_rr)) \n",
    "print(\"FEBRL_postcode_nc STD: \", statistics.pstdev(FEBRL_postcode_nc)) \n",
    "print(\"FEBRL_postcode_pc STD: \", statistics.pstdev(FEBRL_postcode_pc)) \n",
    "print(\"FEBRL_postcode_rr STD: \", statistics.pstdev(FEBRL_postcode_rr)) \n",
    "print(\"FEBRL_all_nc STD: \", statistics.pstdev(FEBRL_all_nc)) \n",
    "print(\"FEBRL_all_pc STD: \", statistics.pstdev(FEBRL_all_pc))\n",
    "print(\"FEBRL_all_rr STD: \", statistics.pstdev(FEBRL_all_rr)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Results: Creating the Paper’s Table 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Mean of classification performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 849 µs, sys: 5 µs, total: 854 µs\n",
      "Wall time: 111 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_col_MEAN = []\n",
    "pr_col_MEAN.append(sum(FEBRL_svm_pr) / float(len(FEBRL_svm_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_svm_bag_pr) / float(len(FEBRL_svm_bag_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_nn_pr) / float(len(FEBRL_nn_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_nn_bag_pr) / float(len(FEBRL_nn_bag_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_lr_pr) / float(len(FEBRL_lr_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_lr_bag_pr) / float(len(FEBRL_lr_bag_pr)))\n",
    "pr_col_MEAN.append(sum(FEBRL_ensemble_pr) / float(len(FEBRL_ensemble_pr)))\n",
    "\n",
    "re_col_MEAN = []\n",
    "re_col_MEAN.append(sum(FEBRL_svm_re) / float(len(FEBRL_svm_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_svm_bag_re) / float(len(FEBRL_svm_bag_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_nn_re) / float(len(FEBRL_nn_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_nn_bag_re) / float(len(FEBRL_nn_bag_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_lr_re) / float(len(FEBRL_lr_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_lr_bag_re) / float(len(FEBRL_lr_bag_re)))\n",
    "re_col_MEAN.append(sum(FEBRL_ensemble_re) / float(len(FEBRL_ensemble_re)))\n",
    "\n",
    "fs_col_MEAN = []\n",
    "fs_col_MEAN.append(sum(FEBRL_svm_fs) / float(len(FEBRL_svm_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_svm_bag_fs) / float(len(FEBRL_svm_bag_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_nn_fs) / float(len(FEBRL_nn_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_nn_bag_fs) / float(len(FEBRL_nn_bag_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_lr_fs) / float(len(FEBRL_lr_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_lr_bag_fs) / float(len(FEBRL_lr_bag_fs)))\n",
    "fs_col_MEAN.append(sum(FEBRL_ensemble_fs) / float(len(FEBRL_ensemble_fs)))\n",
    "\n",
    "fc_col_MEAN = []\n",
    "fc_col_MEAN.append(sum(FEBRL_svm_fc) / float(len(FEBRL_svm_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_svm_bag_fc) / float(len(FEBRL_svm_bag_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_nn_fc) / float(len(FEBRL_nn_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_nn_bag_fc) / float(len(FEBRL_nn_bag_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_lr_fc) / float(len(FEBRL_lr_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_lr_bag_fc) / float(len(FEBRL_lr_bag_fc)))\n",
    "fc_col_MEAN.append(sum(FEBRL_ensemble_fc) / float(len(FEBRL_ensemble_fc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.48 ms, sys: 234 µs, total: 8.72 ms\n",
      "Wall time: 2.66 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = ['SVM', 'SVM-bag', 'NN', 'NN-bag', 'LR', 'LR-bag', 'Stack+Bag']\n",
    "df_means = pd.DataFrame(models, columns=['Model'])\n",
    "df_means['pr(%)'] = pr_col_MEAN\n",
    "df_means['pr(%)'] = df_means['pr(%)']*100\n",
    "df_means['re(%)'] = re_col_MEAN\n",
    "df_means['re(%)'] = df_means['re(%)']*100\n",
    "df_means['fs(%)'] = fs_col_MEAN\n",
    "df_means['fs(%)'] = df_means['fs(%)']*100\n",
    "df_means['fc'] = fc_col_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>89.542540</td>\n",
       "      <td>99.775235</td>\n",
       "      <td>94.382234</td>\n",
       "      <td>581.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>89.534456</td>\n",
       "      <td>99.775235</td>\n",
       "      <td>94.377710</td>\n",
       "      <td>581.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>93.534200</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>96.544316</td>\n",
       "      <td>349.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>93.737043</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>96.652281</td>\n",
       "      <td>338.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>89.283740</td>\n",
       "      <td>99.765018</td>\n",
       "      <td>94.233058</td>\n",
       "      <td>597.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>89.932994</td>\n",
       "      <td>99.762975</td>\n",
       "      <td>94.592554</td>\n",
       "      <td>558.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>94.602185</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>97.109992</td>\n",
       "      <td>290.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model      pr(%)      re(%)      fs(%)     fc\n",
       "0        SVM  89.542540  99.775235  94.382234  581.3\n",
       "1    SVM-bag  89.534456  99.775235  94.377710  581.8\n",
       "2         NN  93.534200  99.754802  96.544316  349.5\n",
       "3     NN-bag  93.737043  99.754802  96.652281  338.2\n",
       "4         LR  89.283740  99.765018  94.233058  597.7\n",
       "5     LR-bag  89.932994  99.762975  94.592554  558.3\n",
       "6  Stack+Bag  94.602185  99.754802  97.109992  290.6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 STD of classification performance after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 ms, sys: 307 µs, total: 39.3 ms\n",
      "Wall time: 4.93 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr_col_STD = []\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_svm_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_svm_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_nn_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_nn_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_lr_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_lr_bag_pr))\n",
    "pr_col_STD.append(statistics.pstdev(FEBRL_ensemble_pr))\n",
    "\n",
    "re_col_STD = []\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_svm_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_svm_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_nn_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_nn_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_lr_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_lr_bag_re))\n",
    "re_col_STD.append(statistics.pstdev(FEBRL_ensemble_re))\n",
    "\n",
    "fs_col_STD = []\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_svm_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_svm_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_nn_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_nn_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_lr_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_lr_bag_fs))\n",
    "fs_col_STD.append(statistics.pstdev(FEBRL_ensemble_fs))\n",
    "\n",
    "fc_col_STD = []\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_svm_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_svm_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_nn_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_nn_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_lr_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_lr_bag_fc))\n",
    "fc_col_STD.append(statistics.pstdev(FEBRL_ensemble_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 ms, sys: 1.2 ms, total: 24.4 ms\n",
      "Wall time: 3.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_STD = pd.DataFrame(models, columns=['Model'])\n",
    "df_STD['pr(%)'] = pr_col_STD\n",
    "df_STD['pr(%)'] = df_STD['pr(%)']*100\n",
    "df_STD['re(%)'] = re_col_STD\n",
    "df_STD['re(%)'] = df_STD['re(%)']*100\n",
    "df_STD['fs(%)'] = fs_col_STD\n",
    "df_STD['fs(%)'] = df_STD['fs(%)']*100\n",
    "df_STD['fc'] = fc_col_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.195880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108686</td>\n",
       "      <td>11.874342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>0.222846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123597</td>\n",
       "      <td>13.490738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.177631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094576</td>\n",
       "      <td>9.899495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>0.150931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080242</td>\n",
       "      <td>8.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.508650</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.283564</td>\n",
       "      <td>31.288976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>0.499466</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.275485</td>\n",
       "      <td>30.149627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>0.271923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143299</td>\n",
       "      <td>14.832397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model     pr(%)     re(%)     fs(%)         fc\n",
       "0        SVM  0.195880  0.000000  0.108686  11.874342\n",
       "1    SVM-bag  0.222846  0.000000  0.123597  13.490738\n",
       "2         NN  0.177631  0.000000  0.094576   9.899495\n",
       "3     NN-bag  0.150931  0.000000  0.080242   8.366600\n",
       "4         LR  0.508650  0.010217  0.283564  31.288976\n",
       "5     LR-bag  0.499466  0.010010  0.275485  30.149627\n",
       "6  Stack+Bag  0.271923  0.000000  0.143299  14.832397"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Comparing if the paper's results for classification performance fall within two standard deviations of the reproduced results after 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.2 ms, sys: 1.14 ms, total: 47.3 ms\n",
      "Wall time: 5.87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_lower_and_upper = pd.DataFrame(models, columns=['Model'])\n",
    "df_lower_and_upper['pr(%)_lower'] = df_means['pr(%)'] - 2 * df_STD['pr(%)']\n",
    "df_lower_and_upper['pr(%)_uppper'] = df_means['pr(%)'] + 2 * df_STD['pr(%)']    \n",
    "df_lower_and_upper['re(%)_lower'] = df_means['re(%)'] - 2 * df_STD['re(%)']\n",
    "df_lower_and_upper['re(%)_uppper'] = df_means['re(%)'] + 2 * df_STD['re(%)'] \n",
    "df_lower_and_upper['fs(%)_lower'] = df_means['fs(%)'] - 2 * df_STD['fs(%)']\n",
    "df_lower_and_upper['fs(%)_uppper'] = df_means['fs(%)'] + 2 * df_STD['fs(%)']\n",
    "df_lower_and_upper['fc_lower'] = df_means['fc'] - 2 * df_STD['fc']\n",
    "df_lower_and_upper['fc_uppper'] = df_means['fc'] + 2 * df_STD['fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)_lower</th>\n",
       "      <th>pr(%)_uppper</th>\n",
       "      <th>re(%)_lower</th>\n",
       "      <th>re(%)_uppper</th>\n",
       "      <th>fs(%)_lower</th>\n",
       "      <th>fs(%)_uppper</th>\n",
       "      <th>fc_lower</th>\n",
       "      <th>fc_uppper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>89.150779</td>\n",
       "      <td>89.934300</td>\n",
       "      <td>99.775235</td>\n",
       "      <td>99.775235</td>\n",
       "      <td>94.164862</td>\n",
       "      <td>94.599607</td>\n",
       "      <td>557.551316</td>\n",
       "      <td>605.048684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>89.088763</td>\n",
       "      <td>89.980148</td>\n",
       "      <td>99.775235</td>\n",
       "      <td>99.775235</td>\n",
       "      <td>94.130517</td>\n",
       "      <td>94.624904</td>\n",
       "      <td>554.818525</td>\n",
       "      <td>608.781475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>93.178939</td>\n",
       "      <td>93.889462</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>96.355163</td>\n",
       "      <td>96.733468</td>\n",
       "      <td>329.701010</td>\n",
       "      <td>369.298990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>93.435181</td>\n",
       "      <td>94.038905</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>96.491797</td>\n",
       "      <td>96.812765</td>\n",
       "      <td>321.466799</td>\n",
       "      <td>354.933201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>88.266440</td>\n",
       "      <td>90.301039</td>\n",
       "      <td>99.744585</td>\n",
       "      <td>99.785452</td>\n",
       "      <td>93.665930</td>\n",
       "      <td>94.800185</td>\n",
       "      <td>535.122049</td>\n",
       "      <td>660.277951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>88.934063</td>\n",
       "      <td>90.931925</td>\n",
       "      <td>99.742955</td>\n",
       "      <td>99.782995</td>\n",
       "      <td>94.041583</td>\n",
       "      <td>95.143524</td>\n",
       "      <td>498.000746</td>\n",
       "      <td>618.599254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>94.058339</td>\n",
       "      <td>95.146031</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>99.754802</td>\n",
       "      <td>96.823395</td>\n",
       "      <td>97.396589</td>\n",
       "      <td>260.935206</td>\n",
       "      <td>320.264794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  pr(%)_lower  pr(%)_uppper  re(%)_lower  re(%)_uppper  \\\n",
       "0        SVM    89.150779     89.934300    99.775235     99.775235   \n",
       "1    SVM-bag    89.088763     89.980148    99.775235     99.775235   \n",
       "2         NN    93.178939     93.889462    99.754802     99.754802   \n",
       "3     NN-bag    93.435181     94.038905    99.754802     99.754802   \n",
       "4         LR    88.266440     90.301039    99.744585     99.785452   \n",
       "5     LR-bag    88.934063     90.931925    99.742955     99.782995   \n",
       "6  Stack+Bag    94.058339     95.146031    99.754802     99.754802   \n",
       "\n",
       "   fs(%)_lower  fs(%)_uppper    fc_lower   fc_uppper  \n",
       "0    94.164862     94.599607  557.551316  605.048684  \n",
       "1    94.130517     94.624904  554.818525  608.781475  \n",
       "2    96.355163     96.733468  329.701010  369.298990  \n",
       "3    96.491797     96.812765  321.466799  354.933201  \n",
       "4    93.665930     94.800185  535.122049  660.277951  \n",
       "5    94.041583     95.143524  498.000746  618.599254  \n",
       "6    96.823395     97.396589  260.935206  320.264794  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lower_and_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 ms, sys: 218 µs, total: 2.38 ms\n",
      "Wall time: 2.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_authors_values = pd.DataFrame(models, columns=['Model'])\n",
    "df_authors_values['pr(%)'] = [94.85, 95.46, 92.80, 92.75, 84.46, 84.27, 96.97]\n",
    "df_authors_values['re(%)'] = [99.73, 99.73, 99.59, 99.57, 99.69, 99.69, 99.43]\n",
    "df_authors_values['fs(%)'] = [97.23, 97.55, 96.08, 96.04, 91.44, 91.33, 98.18]\n",
    "df_authors_values['fc'] = [278, 245, 398, 402, 913, 926, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr(%)</th>\n",
       "      <th>re(%)</th>\n",
       "      <th>fs(%)</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>94.85</td>\n",
       "      <td>99.73</td>\n",
       "      <td>97.23</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>95.46</td>\n",
       "      <td>99.73</td>\n",
       "      <td>97.55</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>92.80</td>\n",
       "      <td>99.59</td>\n",
       "      <td>96.08</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>92.75</td>\n",
       "      <td>99.57</td>\n",
       "      <td>96.04</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>84.46</td>\n",
       "      <td>99.69</td>\n",
       "      <td>91.44</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>84.27</td>\n",
       "      <td>99.69</td>\n",
       "      <td>91.33</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>96.97</td>\n",
       "      <td>99.43</td>\n",
       "      <td>98.18</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  pr(%)  re(%)  fs(%)   fc\n",
       "0        SVM  94.85  99.73  97.23  278\n",
       "1    SVM-bag  95.46  99.73  97.55  245\n",
       "2         NN  92.80  99.59  96.08  398\n",
       "3     NN-bag  92.75  99.57  96.04  402\n",
       "4         LR  84.46  99.69  91.44  913\n",
       "5     LR-bag  84.27  99.69  91.33  926\n",
       "6  Stack+Bag  96.97  99.43  98.18  180"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.59 ms, sys: 344 µs, total: 3.93 ms\n",
      "Wall time: 3.69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "within_2_std = pd.DataFrame(models, columns=['Model'])\n",
    "within_2_std['pr'] = (df_authors_values['pr(%)'] >= df_lower_and_upper['pr(%)_lower']) & (df_authors_values['pr(%)'] <= df_lower_and_upper['pr(%)_uppper'])\n",
    "within_2_std['re'] = (df_authors_values['re(%)'] >= df_lower_and_upper['re(%)_lower']) & (df_authors_values['re(%)'] <= df_lower_and_upper['re(%)_uppper'])\n",
    "within_2_std['fs'] = (df_authors_values['fs(%)'] >= df_lower_and_upper['fs(%)_lower']) & (df_authors_values['fs(%)'] <= df_lower_and_upper['fs(%)_uppper'])\n",
    "within_2_std['fc'] = (df_authors_values['fc'] >= df_lower_and_upper['fc_lower']) & (df_authors_values['fc'] <= df_lower_and_upper['fc_uppper'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>pr</th>\n",
       "      <th>re</th>\n",
       "      <th>fs</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR-bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stack+Bag</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model     pr     re     fs     fc\n",
       "0        SVM  False  False  False  False\n",
       "1    SVM-bag  False  False  False  False\n",
       "2         NN  False  False  False  False\n",
       "3     NN-bag  False  False  False  False\n",
       "4         LR  False  False  False  False\n",
       "5     LR-bag  False  False  False  False\n",
       "6  Stack+Bag  False  False  False  False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True = the paper results fall within 2 standard deviations of the mean according to the reproduce results\n",
    "# False = the paper results don't fall within 2 standard deviations of the mean according to the reproduce results\n",
    "within_2_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
